{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3be019a5",
   "metadata": {
    "papermill": {
     "duration": 62.614393,
     "end_time": "2024-08-17T05:16:22.895811",
     "exception": false,
     "start_time": "2024-08-17T05:15:20.281418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install ray==2.10.0\n",
    "# !pip install autogluon.tabular\n",
    "# !pip install -U ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cea3e09e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-17T05:16:22.920317Z",
     "iopub.status.busy": "2024-08-17T05:16:22.919935Z",
     "iopub.status.idle": "2024-08-17T05:16:26.140266Z",
     "shell.execute_reply": "2024-08-17T05:16:26.139283Z"
    },
    "papermill": {
     "duration": 3.236049,
     "end_time": "2024-08-17T05:16:26.143550",
     "exception": false,
     "start_time": "2024-08-17T05:16:22.907501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f192b12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-17T05:16:26.164805Z",
     "iopub.status.busy": "2024-08-17T05:16:26.164278Z",
     "iopub.status.idle": "2024-08-17T05:16:36.260265Z",
     "shell.execute_reply": "2024-08-17T05:16:36.259291Z"
    },
    "papermill": {
     "duration": 10.108636,
     "end_time": "2024-08-17T05:16:36.262292",
     "exception": false,
     "start_time": "2024-08-17T05:16:26.153656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>...</th>\n",
       "      <th>stem-root</th>\n",
       "      <th>stem-surface</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e</td>\n",
       "      <td>8.80</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "      <td>f</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>w</td>\n",
       "      <td>4.51</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p</td>\n",
       "      <td>4.51</td>\n",
       "      <td>x</td>\n",
       "      <td>h</td>\n",
       "      <td>o</td>\n",
       "      <td>f</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>4.79</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>o</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e</td>\n",
       "      <td>6.94</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>b</td>\n",
       "      <td>f</td>\n",
       "      <td>x</td>\n",
       "      <td>c</td>\n",
       "      <td>w</td>\n",
       "      <td>6.85</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>l</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e</td>\n",
       "      <td>3.88</td>\n",
       "      <td>f</td>\n",
       "      <td>y</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>g</td>\n",
       "      <td>4.16</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>5.85</td>\n",
       "      <td>x</td>\n",
       "      <td>l</td>\n",
       "      <td>w</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>3.37</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>g</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class  cap-diameter cap-shape cap-surface cap-color does-bruise-or-bleed  \\\n",
       "0     e          8.80         f           s         u                    f   \n",
       "1     p          4.51         x           h         o                    f   \n",
       "2     e          6.94         f           s         b                    f   \n",
       "3     e          3.88         f           y         g                    f   \n",
       "4     e          5.85         x           l         w                    f   \n",
       "\n",
       "  gill-attachment gill-spacing gill-color  stem-height  ...  stem-root  \\\n",
       "0               a            c          w         4.51  ...        NaN   \n",
       "1               a            c          n         4.79  ...        NaN   \n",
       "2               x            c          w         6.85  ...        NaN   \n",
       "3               s          NaN          g         4.16  ...        NaN   \n",
       "4               d          NaN          w         3.37  ...        NaN   \n",
       "\n",
       "  stem-surface stem-color veil-type veil-color has-ring ring-type  \\\n",
       "0          NaN          w       NaN        NaN        f         f   \n",
       "1            y          o       NaN        NaN        t         z   \n",
       "2            s          n       NaN        NaN        f         f   \n",
       "3          NaN          w       NaN        NaN        f         f   \n",
       "4          NaN          w       NaN        NaN        f         f   \n",
       "\n",
       "  spore-print-color habitat season  \n",
       "0               NaN       d      a  \n",
       "1               NaN       d      w  \n",
       "2               NaN       l      w  \n",
       "3               NaN       d      u  \n",
       "4               NaN       g      a  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/playground-series-s4e8/train.csv').drop('id', axis=1)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "109cd7a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-17T05:16:36.283606Z",
     "iopub.status.busy": "2024-08-17T05:16:36.283026Z",
     "iopub.status.idle": "2024-08-17T05:16:42.916419Z",
     "shell.execute_reply": "2024-08-17T05:16:42.915391Z"
    },
    "papermill": {
     "duration": 6.646279,
     "end_time": "2024-08-17T05:16:42.918661",
     "exception": false,
     "start_time": "2024-08-17T05:16:36.272382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>stem-width</th>\n",
       "      <th>stem-root</th>\n",
       "      <th>stem-surface</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.64</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>11.13</td>\n",
       "      <td>17.12</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>u</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.90</td>\n",
       "      <td>o</td>\n",
       "      <td>t</td>\n",
       "      <td>o</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c</td>\n",
       "      <td>y</td>\n",
       "      <td>1.27</td>\n",
       "      <td>10.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.00</td>\n",
       "      <td>b</td>\n",
       "      <td>g</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>6.18</td>\n",
       "      <td>3.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.47</td>\n",
       "      <td>x</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>4.98</td>\n",
       "      <td>8.51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.17</td>\n",
       "      <td>x</td>\n",
       "      <td>h</td>\n",
       "      <td>y</td>\n",
       "      <td>f</td>\n",
       "      <td>p</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>6.73</td>\n",
       "      <td>13.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cap-diameter cap-shape cap-surface cap-color does-bruise-or-bleed  \\\n",
       "0          8.64         x         NaN         n                    t   \n",
       "1          6.90         o           t         o                    f   \n",
       "2          2.00         b           g         n                    f   \n",
       "3          3.47         x           t         n                    f   \n",
       "4          6.17         x           h         y                    f   \n",
       "\n",
       "  gill-attachment gill-spacing gill-color  stem-height  stem-width stem-root  \\\n",
       "0             NaN          NaN          w        11.13       17.12         b   \n",
       "1             NaN            c          y         1.27       10.75       NaN   \n",
       "2             NaN            c          n         6.18        3.14       NaN   \n",
       "3               s            c          n         4.98        8.51       NaN   \n",
       "4               p          NaN          y         6.73       13.70       NaN   \n",
       "\n",
       "  stem-surface stem-color veil-type veil-color has-ring ring-type  \\\n",
       "0          NaN          w         u          w        t         g   \n",
       "1          NaN          n       NaN        NaN        f         f   \n",
       "2          NaN          n       NaN        NaN        f         f   \n",
       "3          NaN          w       NaN          n        t         z   \n",
       "4          NaN          y       NaN          y        t       NaN   \n",
       "\n",
       "  spore-print-color habitat season  \n",
       "0               NaN       d      a  \n",
       "1               NaN       d      a  \n",
       "2               NaN       d      s  \n",
       "3               NaN       d      u  \n",
       "4               NaN       d      u  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('/kaggle/input/playground-series-s4e8/test.csv').drop('id', axis=1)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22cf9eab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-17T05:16:42.941151Z",
     "iopub.status.busy": "2024-08-17T05:16:42.940832Z",
     "iopub.status.idle": "2024-08-17T15:17:59.376734Z",
     "shell.execute_reply": "2024-08-17T15:17:59.375680Z"
    },
    "papermill": {
     "duration": 36076.449308,
     "end_time": "2024-08-17T15:17:59.378974",
     "exception": false,
     "start_time": "2024-08-17T05:16:42.929666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20240817_051642\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.10.13\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Thu Jun 27 20:43:36 UTC 2024\n",
      "CPU Count:          4\n",
      "Memory Avail:       29.00 GB / 31.36 GB (92.5%)\n",
      "Disk Space Avail:   19.50 GB / 19.52 GB (99.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 9000s of the 36000s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2024-08-17 05:16:47,173\tINFO worker.py:1752 -- Started a local Ray instance.\n",
      "\t\tContext path: \"AutogluonModels/ag-20240817_051642/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Beginning AutoGluon training ... Time limit = 8995s\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m AutoGluon will save models to \"AutogluonModels/ag-20240817_051642/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Train Data Rows:    2770617\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Train Data Columns: 20\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Label Column:       class\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Problem Type:       binary\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Selected class <--> label mapping:  class 1 = p, class 0 = e\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (p) vs negative (e) class.\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tAvailable Memory:                    29341.45 MB\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tTrain Data (Original)  Memory Usage: 2319.00 MB (7.9% of available memory)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tWarning: Data size prior to feature transformation consumes 7.9% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t\t('float', [])  :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t\t('object', []) : 17 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t\t('category', []) : 17 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t\t('float', [])    :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t40.0s = Fit runtime\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t20 features in original data used to generate 20 features in processed data.\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tTrain Data (Processed) Memory Usage: 108.34 MB (0.4% of available memory)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Data preprocessing and feature engineering runtime = 47.18s ...\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'mcc'\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Fitting 108 L1 models ...\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 5963.39s of the 8947.31s of remaining time.\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=3.21%)\n",
      "\u001b[36m(_ray_fit pid=590)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=590)\u001b[0m 1 warning generated.\n",
      "\u001b[36m(_ray_fit pid=589)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=590)\u001b[0m 1 warning generated.\u001b[32m [repeated 58x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=589)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0365728\tvalid_set's mcc: 0.984198\n",
      "\u001b[36m(_ray_fit pid=589)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.0360659\tvalid_set's mcc: 0.984506\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=590)\u001b[0m [3000]\tvalid_set's binary_logloss: 0.035406\tvalid_set's mcc: 0.98488\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=589)\u001b[0m \tRan out of time, early stopping on iteration 3915. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=589)\u001b[0m \t[3647]\tvalid_set's binary_logloss: 0.0359025\tvalid_set's mcc: 0.984634\n",
      "\u001b[36m(_ray_fit pid=589)\u001b[0m 1 warning generated.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=664)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=590)\u001b[0m \tRan out of time, early stopping on iteration 3937. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=590)\u001b[0m \t[3543]\tvalid_set's binary_logloss: 0.0353759\tvalid_set's mcc: 0.984956\n",
      "\u001b[36m(_ray_fit pid=699)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=664)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0363292\tvalid_set's mcc: 0.98443\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=699)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0363829\tvalid_set's mcc: 0.984337\n",
      "\u001b[36m(_ray_fit pid=664)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.0358444\tvalid_set's mcc: 0.984797\n",
      "\u001b[36m(_ray_fit pid=699)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.035958\tvalid_set's mcc: 0.984611\n",
      "\u001b[36m(_ray_fit pid=664)\u001b[0m [3000]\tvalid_set's binary_logloss: 0.0357384\tvalid_set's mcc: 0.984885\n",
      "\u001b[36m(_ray_fit pid=699)\u001b[0m [3000]\tvalid_set's binary_logloss: 0.0358824\tvalid_set's mcc: 0.984622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=664)\u001b[0m \tRan out of time, early stopping on iteration 3990. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=664)\u001b[0m \t[3831]\tvalid_set's binary_logloss: 0.0357229\tvalid_set's mcc: 0.98496\n",
      "\u001b[36m(_ray_fit pid=746)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=787)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=746)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0370816\tvalid_set's mcc: 0.983918\n",
      "\u001b[36m(_ray_fit pid=787)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0361509\tvalid_set's mcc: 0.984549\n",
      "\u001b[36m(_ray_fit pid=746)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.0365701\tvalid_set's mcc: 0.984198\n",
      "\u001b[36m(_ray_fit pid=787)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.0357109\tvalid_set's mcc: 0.984863\n",
      "\u001b[36m(_ray_fit pid=746)\u001b[0m [3000]\tvalid_set's binary_logloss: 0.0364206\tvalid_set's mcc: 0.98429\n",
      "\u001b[36m(_ray_fit pid=787)\u001b[0m [3000]\tvalid_set's binary_logloss: 0.0355733\tvalid_set's mcc: 0.984916\n",
      "\u001b[36m(_ray_fit pid=746)\u001b[0m [4000]\tvalid_set's binary_logloss: 0.0363959\tvalid_set's mcc: 0.984279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=746)\u001b[0m \tRan out of time, early stopping on iteration 4018. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=746)\u001b[0m \t[3201]\tvalid_set's binary_logloss: 0.0364091\tvalid_set's mcc: 0.984314\n",
      "\u001b[36m(_ray_fit pid=828)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=787)\u001b[0m \tRan out of time, early stopping on iteration 3938. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=787)\u001b[0m \t[3890]\tvalid_set's binary_logloss: 0.0355447\tvalid_set's mcc: 0.984986\n",
      "\u001b[36m(_ray_fit pid=869)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=828)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0373678\tvalid_set's mcc: 0.984197\n",
      "\u001b[36m(_ray_fit pid=869)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0365551\tvalid_set's mcc: 0.984501\n",
      "\u001b[36m(_ray_fit pid=828)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.0369035\tvalid_set's mcc: 0.984507\n",
      "\u001b[36m(_ray_fit pid=869)\u001b[0m [2000]\tvalid_set's binary_logloss: 0.0361498\tvalid_set's mcc: 0.984687\n",
      "\u001b[36m(_ray_fit pid=828)\u001b[0m [3000]\tvalid_set's binary_logloss: 0.0367914\tvalid_set's mcc: 0.984565\n",
      "\u001b[36m(_ray_fit pid=869)\u001b[0m [3000]\tvalid_set's binary_logloss: 0.0360616\tvalid_set's mcc: 0.984833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=828)\u001b[0m \tRan out of time, early stopping on iteration 3987. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=828)\u001b[0m \t[3677]\tvalid_set's binary_logloss: 0.0367622\tvalid_set's mcc: 0.984617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=869)\u001b[0m [4000]\tvalid_set's binary_logloss: 0.0360699\tvalid_set's mcc: 0.984856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=869)\u001b[0m \tRan out of time, early stopping on iteration 4001. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=869)\u001b[0m \t[3893]\tvalid_set's binary_logloss: 0.0360613\tvalid_set's mcc: 0.98488\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t0.9848\t = Validation score   (mcc)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t5210.87s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t1062.51s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 607.19s of the 3591.11s of remaining time.\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=3.24%)\n",
      "\u001b[36m(_ray_fit pid=1145)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1146)\u001b[0m \tRan out of time, early stopping on iteration 261. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1146)\u001b[0m \t[261]\tvalid_set's binary_logloss: 0.0399525\tvalid_set's mcc: 0.982131\n",
      "\u001b[36m(_ray_fit pid=1146)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1220)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1145)\u001b[0m \tRan out of time, early stopping on iteration 260. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1145)\u001b[0m \t[258]\tvalid_set's binary_logloss: 0.0404489\tvalid_set's mcc: 0.982182\n",
      "\u001b[36m(_ray_fit pid=1220)\u001b[0m \tRan out of time, early stopping on iteration 259. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1220)\u001b[0m \t[259]\tvalid_set's binary_logloss: 0.0399968\tvalid_set's mcc: 0.982385\n",
      "\u001b[36m(_ray_fit pid=1228)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1303)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1228)\u001b[0m \tRan out of time, early stopping on iteration 257. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1228)\u001b[0m \t[255]\tvalid_set's binary_logloss: 0.040469\tvalid_set's mcc: 0.98205\n",
      "\u001b[36m(_ray_fit pid=1303)\u001b[0m \tRan out of time, early stopping on iteration 261. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1303)\u001b[0m \t[260]\tvalid_set's binary_logloss: 0.0409706\tvalid_set's mcc: 0.981705\n",
      "\u001b[36m(_ray_fit pid=1311)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1386)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1311)\u001b[0m \tRan out of time, early stopping on iteration 258. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1311)\u001b[0m \t[258]\tvalid_set's binary_logloss: 0.0403622\tvalid_set's mcc: 0.982046\n",
      "\u001b[36m(_ray_fit pid=1386)\u001b[0m \tRan out of time, early stopping on iteration 257. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1386)\u001b[0m \t[257]\tvalid_set's binary_logloss: 0.0412013\tvalid_set's mcc: 0.981513\n",
      "\u001b[36m(_ray_fit pid=1418)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t0.982\t = Validation score   (mcc)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t533.98s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t79.7s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 59.3s of the 3043.21s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=1418)\u001b[0m \tRan out of time, early stopping on iteration 258. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=1418)\u001b[0m \t[258]\tvalid_set's binary_logloss: 0.0401379\tvalid_set's mcc: 0.982249\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tWarning: Model is expected to require 960.4s to train, which exceeds the maximum time limit of 59.3s, skipping model...\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tTime limit exceeded... Skipping RandomForestGini_BAG_L1.\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 45.33s of the 3029.24s of remaining time.\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tWarning: Model is expected to require 1092.7s to train, which exceeds the maximum time limit of 45.3s, skipping model...\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tTime limit exceeded... Skipping RandomForestEntr_BAG_L1.\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 29.67s of the 3013.58s of remaining time.\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=3.30%)\n",
      "\u001b[36m(_ray_fit pid=1717)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1717)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Failed to unpickle serialized exception\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/exceptions.py\", line 46, in from_ray_exception\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     return pickle.loads(ray_exception.serialized_exception)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m ModuleNotFoundError: No module named '_catboost'\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \n",
      "\u001b[36m(_dystack pid=195)\u001b[0m The above exception was the direct cause of the following exception:\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/serialization.py\", line 404, in deserialize_objects\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     obj = self._deserialize_object(data, metadata, object_ref)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/serialization.py\", line 293, in _deserialize_object\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     return RayError.from_bytes(obj)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/exceptions.py\", line 40, in from_bytes\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     return RayError.from_ray_exception(ray_exception)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/exceptions.py\", line 49, in from_ray_exception\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     raise RuntimeError(msg) from e\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m RuntimeError: Failed to unpickle serialized exception\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tWarning: Exception caused CatBoost_BAG_L1 to fail during training... Skipping this model.\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t\tSystem error: Failed to unpickle serialized exception\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m traceback: Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/exceptions.py\", line 46, in from_ray_exception\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     return pickle.loads(ray_exception.serialized_exception)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m ModuleNotFoundError: No module named '_catboost'\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \n",
      "\u001b[36m(_dystack pid=195)\u001b[0m The above exception was the direct cause of the following exception:\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/serialization.py\", line 404, in deserialize_objects\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     obj = self._deserialize_object(data, metadata, object_ref)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/serialization.py\", line 293, in _deserialize_object\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     return RayError.from_bytes(obj)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/exceptions.py\", line 40, in from_bytes\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     return RayError.from_ray_exception(ray_exception)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/exceptions.py\", line 49, in from_ray_exception\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     raise RuntimeError(msg) from e\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m RuntimeError: Failed to unpickle serialized exception\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Detailed Traceback:\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1904, in _train_and_save\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1844, in _train_single\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     out = self._fit(**kwargs)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py\", line 165, in _fit\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     return super()._fit(X=X, y=y, time_limit=time_limit, **kwargs)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 288, in _fit\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     self._fit_folds(\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/bagged_ensemble_model.py\", line 714, in _fit_folds\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     fold_fitting_strategy.after_all_folds_scheduled()\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 668, in after_all_folds_scheduled\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     self._run_parallel(X, y, X_pseudo, y_pseudo, model_base_ref, time_limit_fold, head_node_id)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 610, in _run_parallel\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     self._process_fold_results(finished, unfinished, fold_ctx)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 572, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     raise processed_exception\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 537, in _process_fold_results\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     fold_model, pred_proba, time_start_fit, time_end_fit, predict_time, predict_1_time, predict_n_size = self.ray.get(finished)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     return fn(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     return func(*args, **kwargs)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/worker.py\", line 866, in get_objects\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     raise value\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m ray.exceptions.RaySystemError: System error: Failed to unpickle serialized exception\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m traceback: Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/exceptions.py\", line 46, in from_ray_exception\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     return pickle.loads(ray_exception.serialized_exception)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m ModuleNotFoundError: No module named '_catboost'\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \n",
      "\u001b[36m(_dystack pid=195)\u001b[0m The above exception was the direct cause of the following exception:\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/serialization.py\", line 404, in deserialize_objects\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     obj = self._deserialize_object(data, metadata, object_ref)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/_private/serialization.py\", line 293, in _deserialize_object\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     return RayError.from_bytes(obj)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/exceptions.py\", line 40, in from_bytes\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     return RayError.from_ray_exception(ray_exception)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m   File \"/opt/conda/lib/python3.10/site-packages/ray/exceptions.py\", line 49, in from_ray_exception\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m     raise RuntimeError(msg) from e\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m RuntimeError: Failed to unpickle serialized exception\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \n",
      "\u001b[36m(_ray_fit pid=1718)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=1718)\u001b[0m \tWarning: CatBoost on GPU is experimental. If you encounter issues, use CPU for training CatBoost instead.\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 3.3s of the 2987.22s of remaining time.\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tWarning: Model is expected to require 608.8s to train, which exceeds the maximum time limit of 3.3s, skipping model...\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tTime limit exceeded... Skipping ExtraTreesGini_BAG_L1.\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 596.34s of the 2977.7s of remaining time.\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t0.9848\t = Validation score   (mcc)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t6.91s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t0.46s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Fitting 108 L2 models ...\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 2970.2s of the 2970.04s of remaining time.\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=3.84%)\n",
      "\u001b[36m(_ray_fit pid=2037)\u001b[0m \tTraining S1F2 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2036)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0368099\tvalid_set's mcc: 0.984494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2111)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2036)\u001b[0m \tRan out of time, early stopping on iteration 1890. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=2036)\u001b[0m \t[1888]\tvalid_set's binary_logloss: 0.036674\tvalid_set's mcc: 0.984605\n",
      "\u001b[36m(_ray_fit pid=2152)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2111)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.036165\tvalid_set's mcc: 0.984408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2111)\u001b[0m \tRan out of time, early stopping on iteration 1829. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=2111)\u001b[0m \t[1737]\tvalid_set's binary_logloss: 0.0360363\tvalid_set's mcc: 0.984588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2152)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.036943\tvalid_set's mcc: 0.984327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2194)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=2235)\u001b[0m \tTraining S1F6 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2194)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.036156\tvalid_set's mcc: 0.984811\n",
      "\u001b[36m(_ray_fit pid=2235)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0358915\tvalid_set's mcc: 0.984856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2194)\u001b[0m \tRan out of time, early stopping on iteration 1876. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=2194)\u001b[0m \t[1558]\tvalid_set's binary_logloss: 0.0360354\tvalid_set's mcc: 0.984881\n",
      "\u001b[36m(_ray_fit pid=2276)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=2235)\u001b[0m \tRan out of time, early stopping on iteration 1877. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=2235)\u001b[0m \t[1835]\tvalid_set's binary_logloss: 0.0357852\tvalid_set's mcc: 0.984955\n",
      "\u001b[36m(_ray_fit pid=2317)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2276)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0364094\tvalid_set's mcc: 0.984552\n",
      "\u001b[36m(_ray_fit pid=2317)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0348972\tvalid_set's mcc: 0.984838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=2276)\u001b[0m \tRan out of time, early stopping on iteration 1904. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=2276)\u001b[0m \t[1825]\tvalid_set's binary_logloss: 0.0362863\tvalid_set's mcc: 0.984616\n",
      "\u001b[36m(_ray_fit pid=2317)\u001b[0m \tRan out of time, early stopping on iteration 1852. Best iteration is:\n",
      "\u001b[36m(_ray_fit pid=2317)\u001b[0m \t[1775]\tvalid_set's binary_logloss: 0.0347764\tvalid_set's mcc: 0.985071\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t0.9847\t = Validation score   (mcc)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t2469.41s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t466.22s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 433.19s of the 433.03s of remaining time.\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=3.85%)\n",
      "\u001b[36m(_ray_fit pid=2600)\u001b[0m \tTraining S1F1 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=2675)\u001b[0m \tTraining S1F3 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2717)\u001b[0m \tTraining S1F4 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=2758)\u001b[0m \tTraining S1F5 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_ray_fit pid=2840)\u001b[0m \tTraining S1F7 with GPU, note that this may negatively impact model quality compared to CPU training.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=2876)\u001b[0m \tTraining S1F8 with GPU, note that this may negatively impact model quality compared to CPU training.\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t0.9846\t = Validation score   (mcc)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t133.83s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t3.87s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 293.8s of the 293.64s of remaining time.\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tWarning: Reducing model 'n_estimators' from 300 -> 77 due to low time. Expected time usage reduced from 1132.2s -> 293.8s...\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 220.47s compared to 72.39s of available time.\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tTime limit exceeded... Skipping RandomForestGini_BAG_L2.\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the -17.72s of remaining time.\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t0.9848\t = Validation score   (mcc)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t12.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m \t0.46s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m AutoGluon training complete, total runtime = 9025.61s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 325.9 rows/s (346328 batch size)\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240817_051642/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=195)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      LightGBM_BAG_L2       0.985118   0.984614         mcc      320.434155    1146.084407  5878.684297                 1.924827                3.872624         133.829984            2       True          5\n",
      "1    LightGBMXT_BAG_L1       0.985107   0.984753         mcc      292.652029    1062.510727  5210.870179               292.652029             1062.510727        5210.870179            1       True          1\n",
      "2  WeightedEnsemble_L2       0.985107   0.984753         mcc      292.656753    1062.969386  5217.779527                 0.004723                0.458659           6.909348            2       True          3\n",
      "3  WeightedEnsemble_L3       0.985107   0.984753         mcc      292.657001    1062.969339  5223.419115                 0.004971                0.458612          12.548936            3       True          6\n",
      "4    LightGBMXT_BAG_L2       0.985043   0.984716         mcc      448.284421    1608.435774  8214.265371               129.775093              466.223991        2469.411058            2       True          4\n",
      "5      LightGBM_BAG_L1       0.982475   0.982033         mcc       25.857298      79.701056   533.984133                25.857298               79.701056         533.984133            1       True          2\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t9505s\t = DyStack   runtime |\t26495s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 26495s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20240817_051642\"\n",
      "Train Data Rows:    3116945\n",
      "Train Data Columns: 20\n",
      "Label Column:       class\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = p, class 0 = e\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (p) vs negative (e) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    30952.92 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2608.77 MB (8.4% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 8.4% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
      "\t\t('object', []) : 17 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 17 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
      "\t\t('float', [])    :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
      "\t33.9s = Fit runtime\n",
      "\t20 features in original data used to generate 20 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 121.88 MB (0.4% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 37.37s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mcc'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 108 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 17634.14s of the 26457.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=2.79%)\n",
      "\t0.9849\t = Validation score   (mcc)\n",
      "\t8408.14s\t = Training   runtime\n",
      "\t1408.79s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 9039.28s of the 17862.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=2.79%)\n",
      "\t0.9845\t = Validation score   (mcc)\n",
      "\t4711.51s\t = Training   runtime\n",
      "\t738.17s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 4230.59s of the 13054.26s of remaining time.\n",
      "\t0.9841\t = Validation score   (mcc)\n",
      "\t1086.54s\t = Training   runtime\n",
      "\t114.12s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 3027.39s of the 11851.06s of remaining time.\n",
      "\t0.9842\t = Validation score   (mcc)\n",
      "\t1131.77s\t = Training   runtime\n",
      "\t123.2s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 1769.83s of the 10593.5s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=2.95%)\n",
      "\t0.7705\t = Validation score   (mcc)\n",
      "\t201.85s\t = Training   runtime\n",
      "\t1.46s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 1562.56s of the 10386.23s of remaining time.\n",
      "\t0.9835\t = Validation score   (mcc)\n",
      "\t642.44s\t = Training   runtime\n",
      "\t115.71s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 801.8s of the 9625.47s of remaining time.\n",
      "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 586.8s compared to 377.14s of available time.\n",
      "\tTime limit exceeded... Skipping ExtraTreesEntr_BAG_L1.\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 135.86s of the 8959.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=4.97%)\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L1.\n",
      "2024-08-17 12:47:42,723\tERROR worker.py:406 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): The worker died unexpectedly while executing this task. Check python-core-worker-*.log files for more information.\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 117.05s of the 8940.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=4.03%)\n",
      "\t0.485\t = Validation score   (mcc)\n",
      "\t179.02s\t = Training   runtime\n",
      "\t20.41s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 1763.41s of the 8754.85s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.273, 'RandomForestEntr_BAG_L1': 0.273, 'RandomForestGini_BAG_L1': 0.182, 'XGBoost_BAG_L1': 0.182, 'LightGBM_BAG_L1': 0.091}\n",
      "\t0.9849\t = Validation score   (mcc)\n",
      "\t21.21s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 8732.99s of the 8732.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=4.99%)\n",
      "\t0.9848\t = Validation score   (mcc)\n",
      "\t1148.48s\t = Training   runtime\n",
      "\t130.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 7557.97s of the 7557.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=5.00%)\n",
      "\t0.9848\t = Validation score   (mcc)\n",
      "\t213.29s\t = Training   runtime\n",
      "\t6.58s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 7337.12s of the 7336.81s of remaining time.\n",
      "\t0.985\t = Validation score   (mcc)\n",
      "\t1669.13s\t = Training   runtime\n",
      "\t109.43s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 5554.86s of the 5554.56s of remaining time.\n",
      "\t0.9849\t = Validation score   (mcc)\n",
      "\t2016.84s\t = Training   runtime\n",
      "\t125.69s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 3408.93s of the 3408.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=5.30%)\n",
      "\t0.9848\t = Validation score   (mcc)\n",
      "\t220.75s\t = Training   runtime\n",
      "\t1.36s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 3181.8s of the 3181.5s of remaining time.\n",
      "\t0.985\t = Validation score   (mcc)\n",
      "\t668.04s\t = Training   runtime\n",
      "\t107.74s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 2402.37s of the 2402.08s of remaining time.\n",
      "\t0.985\t = Validation score   (mcc)\n",
      "\t777.41s\t = Training   runtime\n",
      "\t113.31s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 1508.33s of the 1508.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=8.81%)\n",
      "\t0.9849\t = Validation score   (mcc)\n",
      "\t862.33s\t = Training   runtime\n",
      "\t38.67s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 634.6s of the 634.3s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=6.76%)\n",
      "\t0.9849\t = Validation score   (mcc)\n",
      "\t221.65s\t = Training   runtime\n",
      "\t22.74s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 403.85s of the 403.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=4.74%)\n",
      "\t0.9848\t = Validation score   (mcc)\n",
      "\t314.56s\t = Training   runtime\n",
      "\t26.95s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 79.68s of the 79.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2.0 workers, per: cpus=1, gpus=1, memory=5.21%)\n",
      "\t0.9841\t = Validation score   (mcc)\n",
      "\t87.92s\t = Training   runtime\n",
      "\t2.79s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 873.3s of the -18.54s of remaining time.\n",
      "\tEnsemble Weights: {'ExtraTreesEntr_BAG_L2': 0.2, 'NeuralNetFastAI_BAG_L2': 0.2, 'RandomForestGini_BAG_L2': 0.133, 'RandomForestEntr_BAG_L2': 0.133, 'NeuralNetTorch_BAG_L2': 0.133, 'LightGBMLarge_BAG_L2': 0.133, 'XGBoost_BAG_L1': 0.067}\n",
      "\t0.985\t = Validation score   (mcc)\n",
      "\t55.86s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 26570.49s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 167.6 rows/s (389619 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240817_051642\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                      model  score_val eval_metric  pred_time_val      fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0       WeightedEnsemble_L3   0.984991         mcc    2939.121167  22145.313564                0.417520          55.864211            3       True         20\n",
      "1   RandomForestGini_BAG_L2   0.984965         mcc    2631.288702  18030.398024              109.429628        1669.130870            2       True         11\n",
      "2     ExtraTreesEntr_BAG_L2   0.984956         mcc    2635.166399  17138.675040              113.307325         777.407887            2       True         15\n",
      "3     ExtraTreesGini_BAG_L2   0.984951         mcc    2629.600229  17029.307302              107.741155         668.040149            2       True         14\n",
      "4   RandomForestEntr_BAG_L2   0.984946         mcc    2647.553660  18378.104784              125.694587        2016.837630            2       True         12\n",
      "5    NeuralNetFastAI_BAG_L2   0.984923         mcc    2560.532330  17223.594440               38.673256         862.327286            2       True         16\n",
      "6            XGBoost_BAG_L2   0.984874         mcc    2544.603032  16582.920473               22.743958         221.653319            2       True         17\n",
      "7         LightGBMXT_BAG_L1   0.984857         mcc    1408.793692   8408.139899             1408.793692        8408.139899            1       True          1\n",
      "8       WeightedEnsemble_L2   0.984856         mcc    2405.134373  15538.184842                0.442161          21.210239            2       True          8\n",
      "9     NeuralNetTorch_BAG_L2   0.984826         mcc    2548.806643  16675.824259               26.947569         314.557105            2       True         18\n",
      "10          LightGBM_BAG_L2   0.984823         mcc    2528.436921  16574.559685                6.577847         213.292531            2       True         10\n",
      "11        LightGBMXT_BAG_L2   0.984798         mcc    2651.952033  17509.743231              130.092959        1148.476078            2       True          9\n",
      "12          CatBoost_BAG_L2   0.984758         mcc    2523.214427  16582.012922                1.355354         220.745768            2       True         13\n",
      "13          LightGBM_BAG_L1   0.984467         mcc     738.173892   4711.512437              738.173892        4711.512437            1       True          2\n",
      "14  RandomForestEntr_BAG_L1   0.984167         mcc     123.201049   1131.765905              123.201049        1131.765905            1       True          4\n",
      "15  RandomForestGini_BAG_L1   0.984124         mcc     114.118171   1086.536909              114.118171        1086.536909            1       True          3\n",
      "16     LightGBMLarge_BAG_L2   0.984077         mcc    2524.651282  16449.188574                2.792208          87.921421            2       True         19\n",
      "17    ExtraTreesGini_BAG_L1   0.983457         mcc     115.711204    642.444970              115.711204         642.444970            1       True          6\n",
      "18          CatBoost_BAG_L1   0.770451         mcc       1.455658    201.847580                1.455658         201.847580            1       True          5\n",
      "19           XGBoost_BAG_L1   0.485010         mcc      20.405408    179.019453               20.405408         179.019453            1       True          7\n",
      "Number of models trained: 20\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_TabularNeuralNetTorch', 'WeightedEnsembleModel', 'StackerEnsembleModel_CatBoost', 'StackerEnsembleModel_LGB', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_NNFastAiTabular', 'StackerEnsembleModel_XT'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) : 17 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
      "('float', [])    :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
      "Plot summary of models saved to file: AutogluonModels/ag-20240817_051642SummaryOfModels.html\n",
      "*** End of fit() summary ***\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label='class',\n",
    "                            eval_metric='mcc',\n",
    "                            problem_type='binary').fit(train_df,\n",
    "                                                       presets='best_quality',\n",
    "                                                        time_limit=3600*10,\n",
    "                                                       verbosity=2,\n",
    "                                                       excluded_model_types=['KNN'],\n",
    "                                                       ag_args_fit={'num_gpus': 1}\n",
    "                                                      )\n",
    "results = predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "398bd4c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-17T15:17:59.447094Z",
     "iopub.status.busy": "2024-08-17T15:17:59.446192Z",
     "iopub.status.idle": "2024-08-17T15:17:59.476199Z",
     "shell.execute_reply": "2024-08-17T15:17:59.475277Z"
    },
    "papermill": {
     "duration": 0.066095,
     "end_time": "2024-08-17T15:17:59.478404",
     "exception": false,
     "start_time": "2024-08-17T15:17:59.412309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.984991</td>\n",
       "      <td>mcc</td>\n",
       "      <td>2939.121167</td>\n",
       "      <td>22145.313564</td>\n",
       "      <td>0.417520</td>\n",
       "      <td>55.864211</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestGini_BAG_L2</td>\n",
       "      <td>0.984965</td>\n",
       "      <td>mcc</td>\n",
       "      <td>2631.288702</td>\n",
       "      <td>18030.398024</td>\n",
       "      <td>109.429628</td>\n",
       "      <td>1669.130870</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesEntr_BAG_L2</td>\n",
       "      <td>0.984956</td>\n",
       "      <td>mcc</td>\n",
       "      <td>2635.166399</td>\n",
       "      <td>17138.675040</td>\n",
       "      <td>113.307325</td>\n",
       "      <td>777.407887</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ExtraTreesGini_BAG_L2</td>\n",
       "      <td>0.984951</td>\n",
       "      <td>mcc</td>\n",
       "      <td>2629.600229</td>\n",
       "      <td>17029.307302</td>\n",
       "      <td>107.741155</td>\n",
       "      <td>668.040149</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestEntr_BAG_L2</td>\n",
       "      <td>0.984946</td>\n",
       "      <td>mcc</td>\n",
       "      <td>2647.553660</td>\n",
       "      <td>18378.104784</td>\n",
       "      <td>125.694587</td>\n",
       "      <td>2016.837630</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NeuralNetFastAI_BAG_L2</td>\n",
       "      <td>0.984923</td>\n",
       "      <td>mcc</td>\n",
       "      <td>2560.532330</td>\n",
       "      <td>17223.594440</td>\n",
       "      <td>38.673256</td>\n",
       "      <td>862.327286</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost_BAG_L2</td>\n",
       "      <td>0.984874</td>\n",
       "      <td>mcc</td>\n",
       "      <td>2544.603032</td>\n",
       "      <td>16582.920473</td>\n",
       "      <td>22.743958</td>\n",
       "      <td>221.653319</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>0.984857</td>\n",
       "      <td>mcc</td>\n",
       "      <td>1408.793692</td>\n",
       "      <td>8408.139899</td>\n",
       "      <td>1408.793692</td>\n",
       "      <td>8408.139899</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.984856</td>\n",
       "      <td>mcc</td>\n",
       "      <td>2405.134373</td>\n",
       "      <td>15538.184842</td>\n",
       "      <td>0.442161</td>\n",
       "      <td>21.210239</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NeuralNetTorch_BAG_L2</td>\n",
       "      <td>0.984826</td>\n",
       "      <td>mcc</td>\n",
       "      <td>2548.806643</td>\n",
       "      <td>16675.824259</td>\n",
       "      <td>26.947569</td>\n",
       "      <td>314.557105</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>0.984823</td>\n",
       "      <td>mcc</td>\n",
       "      <td>2528.436921</td>\n",
       "      <td>16574.559685</td>\n",
       "      <td>6.577847</td>\n",
       "      <td>213.292531</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>0.984798</td>\n",
       "      <td>mcc</td>\n",
       "      <td>2651.952033</td>\n",
       "      <td>17509.743231</td>\n",
       "      <td>130.092959</td>\n",
       "      <td>1148.476078</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>0.984758</td>\n",
       "      <td>mcc</td>\n",
       "      <td>2523.214427</td>\n",
       "      <td>16582.012922</td>\n",
       "      <td>1.355354</td>\n",
       "      <td>220.745768</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.984467</td>\n",
       "      <td>mcc</td>\n",
       "      <td>738.173892</td>\n",
       "      <td>4711.512437</td>\n",
       "      <td>738.173892</td>\n",
       "      <td>4711.512437</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>0.984167</td>\n",
       "      <td>mcc</td>\n",
       "      <td>123.201049</td>\n",
       "      <td>1131.765905</td>\n",
       "      <td>123.201049</td>\n",
       "      <td>1131.765905</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>0.984124</td>\n",
       "      <td>mcc</td>\n",
       "      <td>114.118171</td>\n",
       "      <td>1086.536909</td>\n",
       "      <td>114.118171</td>\n",
       "      <td>1086.536909</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LightGBMLarge_BAG_L2</td>\n",
       "      <td>0.984077</td>\n",
       "      <td>mcc</td>\n",
       "      <td>2524.651282</td>\n",
       "      <td>16449.188574</td>\n",
       "      <td>2.792208</td>\n",
       "      <td>87.921421</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ExtraTreesGini_BAG_L1</td>\n",
       "      <td>0.983457</td>\n",
       "      <td>mcc</td>\n",
       "      <td>115.711204</td>\n",
       "      <td>642.444970</td>\n",
       "      <td>115.711204</td>\n",
       "      <td>642.444970</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>0.770451</td>\n",
       "      <td>mcc</td>\n",
       "      <td>1.455658</td>\n",
       "      <td>201.847580</td>\n",
       "      <td>1.455658</td>\n",
       "      <td>201.847580</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>0.485010</td>\n",
       "      <td>mcc</td>\n",
       "      <td>20.405408</td>\n",
       "      <td>179.019453</td>\n",
       "      <td>20.405408</td>\n",
       "      <td>179.019453</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      model  score_val eval_metric  pred_time_val  \\\n",
       "0       WeightedEnsemble_L3   0.984991         mcc    2939.121167   \n",
       "1   RandomForestGini_BAG_L2   0.984965         mcc    2631.288702   \n",
       "2     ExtraTreesEntr_BAG_L2   0.984956         mcc    2635.166399   \n",
       "3     ExtraTreesGini_BAG_L2   0.984951         mcc    2629.600229   \n",
       "4   RandomForestEntr_BAG_L2   0.984946         mcc    2647.553660   \n",
       "5    NeuralNetFastAI_BAG_L2   0.984923         mcc    2560.532330   \n",
       "6            XGBoost_BAG_L2   0.984874         mcc    2544.603032   \n",
       "7         LightGBMXT_BAG_L1   0.984857         mcc    1408.793692   \n",
       "8       WeightedEnsemble_L2   0.984856         mcc    2405.134373   \n",
       "9     NeuralNetTorch_BAG_L2   0.984826         mcc    2548.806643   \n",
       "10          LightGBM_BAG_L2   0.984823         mcc    2528.436921   \n",
       "11        LightGBMXT_BAG_L2   0.984798         mcc    2651.952033   \n",
       "12          CatBoost_BAG_L2   0.984758         mcc    2523.214427   \n",
       "13          LightGBM_BAG_L1   0.984467         mcc     738.173892   \n",
       "14  RandomForestEntr_BAG_L1   0.984167         mcc     123.201049   \n",
       "15  RandomForestGini_BAG_L1   0.984124         mcc     114.118171   \n",
       "16     LightGBMLarge_BAG_L2   0.984077         mcc    2524.651282   \n",
       "17    ExtraTreesGini_BAG_L1   0.983457         mcc     115.711204   \n",
       "18          CatBoost_BAG_L1   0.770451         mcc       1.455658   \n",
       "19           XGBoost_BAG_L1   0.485010         mcc      20.405408   \n",
       "\n",
       "        fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
       "0   22145.313564                0.417520          55.864211            3   \n",
       "1   18030.398024              109.429628        1669.130870            2   \n",
       "2   17138.675040              113.307325         777.407887            2   \n",
       "3   17029.307302              107.741155         668.040149            2   \n",
       "4   18378.104784              125.694587        2016.837630            2   \n",
       "5   17223.594440               38.673256         862.327286            2   \n",
       "6   16582.920473               22.743958         221.653319            2   \n",
       "7    8408.139899             1408.793692        8408.139899            1   \n",
       "8   15538.184842                0.442161          21.210239            2   \n",
       "9   16675.824259               26.947569         314.557105            2   \n",
       "10  16574.559685                6.577847         213.292531            2   \n",
       "11  17509.743231              130.092959        1148.476078            2   \n",
       "12  16582.012922                1.355354         220.745768            2   \n",
       "13   4711.512437              738.173892        4711.512437            1   \n",
       "14   1131.765905              123.201049        1131.765905            1   \n",
       "15   1086.536909              114.118171        1086.536909            1   \n",
       "16  16449.188574                2.792208          87.921421            2   \n",
       "17    642.444970              115.711204         642.444970            1   \n",
       "18    201.847580                1.455658         201.847580            1   \n",
       "19    179.019453               20.405408         179.019453            1   \n",
       "\n",
       "    can_infer  fit_order  \n",
       "0        True         20  \n",
       "1        True         11  \n",
       "2        True         15  \n",
       "3        True         14  \n",
       "4        True         12  \n",
       "5        True         16  \n",
       "6        True         17  \n",
       "7        True          1  \n",
       "8        True          8  \n",
       "9        True         18  \n",
       "10       True         10  \n",
       "11       True          9  \n",
       "12       True         13  \n",
       "13       True          2  \n",
       "14       True          4  \n",
       "15       True          3  \n",
       "16       True         19  \n",
       "17       True          6  \n",
       "18       True          5  \n",
       "19       True          7  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31a50221",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-17T15:17:59.547153Z",
     "iopub.status.busy": "2024-08-17T15:17:59.546402Z",
     "iopub.status.idle": "2024-08-17T16:23:13.598278Z",
     "shell.execute_reply": "2024-08-17T16:23:13.597088Z"
    },
    "papermill": {
     "duration": 3914.088553,
     "end_time": "2024-08-17T16:23:13.601066",
     "exception": false,
     "start_time": "2024-08-17T15:17:59.512513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = predictor.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d97f842c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-17T16:23:13.673132Z",
     "iopub.status.busy": "2024-08-17T16:23:13.672148Z",
     "iopub.status.idle": "2024-08-17T16:23:16.915286Z",
     "shell.execute_reply": "2024-08-17T16:23:16.914474Z"
    },
    "papermill": {
     "duration": 3.281224,
     "end_time": "2024-08-17T16:23:16.917698",
     "exception": false,
     "start_time": "2024-08-17T16:23:13.636474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('/kaggle/input/playground-series-s4e8/sample_submission.csv')\n",
    "sub['class'] = y_pred\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9045607,
     "sourceId": 76727,
     "sourceType": "competition"
    },
    {
     "sourceId": 192808909,
     "sourceType": "kernelVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 40085.110711,
   "end_time": "2024-08-17T16:23:22.455976",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-17T05:15:17.345265",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
