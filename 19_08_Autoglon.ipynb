{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "971641aa-0f13-46d1-a549-9d47c11f7afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf391002-4799-4092-b255-60b2c36f6169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "train_df = pd.read_csv('train.csv').drop('id', axis=1)\n",
    "test_df = pd.read_csv('test.csv').drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f911d4cd-ed6e-44f5-a1e3-39ce221fdc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Test to see if TensorFlow can utilize the GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "702407e6-9df2-4c8c-bf49-cc1e87f473d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels\\ag-20240820_151425\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.1\n",
      "Python Version:     3.8.19\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.22631\n",
      "CPU Count:          20\n",
      "Memory Avail:       23.29 GB / 31.82 GB (73.2%)\n",
      "Disk Space Avail:   816.68 GB / 953.00 GB (85.7%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 1350s of the 5400.0s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2024-08-20 19:14:27,741\tINFO worker.py:1752 -- Started a local Ray instance.\n",
      "\t\tContext path: \"AutogluonModels\\ag-20240820_151425\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m Beginning AutoGluon training ... Time limit = 1346s\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m AutoGluon will save models to \"AutogluonModels\\ag-20240820_151425\\ds_sub_fit\\sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m Train Data Rows:    2770617\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m Train Data Columns: 20\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m Label Column:       class\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m Problem Type:       binary\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m Selected class <--> label mapping:  class 1 = p, class 0 = e\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (p) vs negative (e) class.\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \tAvailable Memory:                    22950.87 MB\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \tTrain Data (Original)  Memory Usage: 2319.00 MB (10.1% of available memory)\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \tWarning: Data size prior to feature transformation consumes 10.1% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t\t('float', [])  :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t\t('object', []) : 17 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t\t('category', []) : 17 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t\t('float', [])    :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t16.2s = Fit runtime\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t20 features in original data used to generate 20 features in processed data.\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \tTrain Data (Processed) Memory Usage: 108.34 MB (0.5% of available memory)\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m Data preprocessing and feature engineering runtime = 19.18s ...\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'mcc'\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m Fitting 108 L1 models ...\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 884.07s of the 1326.44s of remaining time.\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=4.09%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_ray_fit pid=4272)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0365551\tvalid_set's mcc: 0.984501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t0.9844\t = Validation score   (mcc)\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t725.77s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t30.31s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 151.24s of the 593.6s of remaining time.\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=4.11%)\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t0.979\t = Validation score   (mcc)\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t129.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t4.76s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 17.97s of the 460.34s of remaining time.\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \tWarning: Model is expected to require 366.8s to train, which exceeds the maximum time limit of 18.0s, skipping model...\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \tTime limit exceeded... Skipping RandomForestGini_BAG_L1.\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 12.3s of the 454.66s of remaining time.\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \tWarning: Model is expected to require 394.9s to train, which exceeds the maximum time limit of 12.3s, skipping model...\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \tTime limit exceeded... Skipping RandomForestEntr_BAG_L1.\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 6.33s of the 448.7s of remaining time.\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=4.12%)\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t0.5343\t = Validation score   (mcc)\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t28.53s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t0.34s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 416.53s of remaining time.\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t0.9844\t = Validation score   (mcc)\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t15.77s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t0.59s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m Fitting 108 L2 models ...\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 400.08s of the 399.96s of remaining time.\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=5.11%)\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t0.9842\t = Validation score   (mcc)\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t331.47s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t10.61s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 63.84s of the 63.72s of remaining time.\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=5.12%)\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t0.9842\t = Validation score   (mcc)\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t50.5s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t0.99s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 8.23s of remaining time.\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.625, 'LightGBMXT_BAG_L2': 0.25, 'LightGBM_BAG_L2': 0.125}\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t0.9844\t = Validation score   (mcc)\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t25.99s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m \t0.61s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m AutoGluon training complete, total runtime = 1364.22s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 7355.7 rows/s (346328 batch size)\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240820_151425\\ds_sub_fit\\sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=10472)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0      LightGBM_BAG_L2       0.984716   0.984222         mcc       18.502380      36.396795   934.340772                 0.972903                0.989537          50.496825            2       True          6\n",
      "1  WeightedEnsemble_L3       0.984641   0.984361         mcc       23.875096      47.612883  1291.800157                 0.015002                0.605390          25.994284            3       True          7\n",
      "2    LightGBMXT_BAG_L1       0.984583   0.984355         mcc       14.064631      30.305207   725.767516                14.064631               30.305207         725.767516            1       True          1\n",
      "3  WeightedEnsemble_L2       0.984583   0.984355         mcc       14.073631      30.893107   741.540174                 0.009001                0.587900          15.772659            2       True          4\n",
      "4    LightGBMXT_BAG_L2       0.984524   0.984156         mcc       22.887192      46.017956  1215.309048                 5.357714               10.610698         331.465100            2       True          5\n",
      "5      LightGBM_BAG_L1       0.979624   0.979048         mcc        2.787837       4.758330   129.545269                 2.787837                4.758330         129.545269            1       True          2\n",
      "6      CatBoost_BAG_L1       0.533890   0.534315         mcc        0.677010       0.343721    28.531163                 0.677010                0.343721          28.531163            1       True          3\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t1402s\t = DyStack   runtime |\t3998s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 3998s\n",
      "AutoGluon will save models to \"AutogluonModels\\ag-20240820_151425\"\n",
      "Train Data Rows:    3116945\n",
      "Train Data Columns: 20\n",
      "Label Column:       class\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = p, class 0 = e\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (p) vs negative (e) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    24555.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2608.77 MB (10.6% of available memory)\n",
      "\tWarning: Data size prior to feature transformation consumes 10.6% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
      "\t\t('object', []) : 17 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 17 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
      "\t\t('float', [])    :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
      "\t12.6s = Fit runtime\n",
      "\t20 features in original data used to generate 20 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 121.88 MB (0.5% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 14.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'mcc'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 108 L1 models ...\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 2655.54s of the 3984.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=3.53%)\n",
      "\t0.9848\t = Validation score   (mcc)\n",
      "\t2164.58s\t = Training   runtime\n",
      "\t77.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 480.34s of the 1809.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=3.52%)\n",
      "\t0.9832\t = Validation score   (mcc)\n",
      "\t397.03s\t = Training   runtime\n",
      "\t15.31s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 78.05s of the 1406.8s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 56 due to low time. Expected time usage reduced from 413.9s -> 78.0s...\n",
      "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 217.91s compared to 23.18s of available time.\n",
      "\tTime limit exceeded... Skipping RandomForestGini_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.0s of the 1327.94s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.9848\t = Validation score   (mcc)\n",
      "\t10.49s\t = Training   runtime\n",
      "\t0.67s\t = Validation runtime\n",
      "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
      "Fitting 108 L2 models ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 1316.69s of the 1316.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=4.24%)\n",
      "\t0.9841\t = Validation score   (mcc)\n",
      "\t819.27s\t = Training   runtime\n",
      "\t28.49s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 489.05s of the 488.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=4.24%)\n",
      "\t0.9845\t = Validation score   (mcc)\n",
      "\t102.03s\t = Training   runtime\n",
      "\t1.57s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 383.13s of the 383.01s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 220 due to low time. Expected time usage reduced from 520.7s -> 383.1s...\n",
      "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 308.67s compared to 176.96s of available time.\n",
      "\tTime limit exceeded... Skipping RandomForestGini_BAG_L2.\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 61.31s of the 61.19s of remaining time.\n",
      "\tWarning: Model is expected to require 541.4s to train, which exceeds the maximum time limit of 61.3s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestEntr_BAG_L2.\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 52.83s of the 52.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (2 workers, per: cpus=10, gpus=0, memory=4.26%)\n",
      "\t0.9844\t = Validation score   (mcc)\n",
      "\t30.7s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 18.26s of the 18.14s of remaining time.\n",
      "\tWarning: Model is expected to require 285.8s to train, which exceeds the maximum time limit of 18.3s, skipping model...\n",
      "\tTime limit exceeded... Skipping ExtraTreesGini_BAG_L2.\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 13.21s of the 13.09s of remaining time.\n",
      "\tWarning: Model is expected to require 295.8s to train, which exceeds the maximum time limit of 13.2s, skipping model...\n",
      "\tTime limit exceeded... Skipping ExtraTreesEntr_BAG_L2.\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 6.77s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L2': 0.45, 'LightGBMXT_BAG_L1': 0.4, 'LightGBMXT_BAG_L2': 0.1, 'LightGBM_BAG_L2': 0.05}\n",
      "\t0.9847\t = Validation score   (mcc)\n",
      "\t26.1s\t = Training   runtime\n",
      "\t0.69s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 4018.68s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 5049.3 rows/s (389619 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels\\ag-20240820_151425\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Summary of fit() ***\n",
      "Estimated performance of each model:\n",
      "                 model  score_val eval_metric  pred_time_val     fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0    LightGBMXT_BAG_L1   0.984757         mcc      77.079024  2164.584958               77.079024        2164.584958            1       True          1\n",
      "1  WeightedEnsemble_L2   0.984757         mcc      77.750646  2175.071465                0.671622          10.486507            2       True          3\n",
      "2  WeightedEnsemble_L3   0.984738         mcc     123.613315  3539.720976                0.685104          26.095592            3       True          7\n",
      "3      LightGBM_BAG_L2   0.984466         mcc      93.957320  2663.651898                1.572998         102.032308            2       True          5\n",
      "4      CatBoost_BAG_L2   0.984427         mcc      92.861315  2592.323455                0.476993          30.703865            2       True          6\n",
      "5    LightGBMXT_BAG_L2   0.984124         mcc     120.878221  3380.889211               28.493898         819.269621            2       True          4\n",
      "6      LightGBM_BAG_L1   0.983230         mcc      15.305299   397.034632               15.305299         397.034632            1       True          2\n",
      "Number of models trained: 7\n",
      "Types of models trained:\n",
      "{'StackerEnsembleModel_LGB', 'StackerEnsembleModel_CatBoost', 'WeightedEnsembleModel'}\n",
      "Bagging used: True  (with 8 folds)\n",
      "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
      "Feature Metadata (Processed):\n",
      "(raw dtype, special dtypes):\n",
      "('category', []) : 17 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
      "('float', [])    :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
      "*** End of fit() summary ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hi\\anaconda3\\envs\\gpu_env\\lib\\site-packages\\autogluon\\core\\utils\\plots.py:169: UserWarning: AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"\n",
      "  warnings.warn('AutoGluon summary plots cannot be created because bokeh is not installed. To see plots, please do: \"pip install bokeh==2.0.1\"')\n"
     ]
    }
   ],
   "source": [
    "# Train the AutoGluon TabularPredictor\n",
    "# Set up the TabularPredictor with GPU and memory optimization\n",
    "predictor = TabularPredictor(\n",
    "    label='class',\n",
    "    eval_metric='mcc',\n",
    "    problem_type='binary'\n",
    ").fit(\n",
    "    train_df,\n",
    "    presets='best_quality',\n",
    "    time_limit=3600 * 1.5,\n",
    "    verbosity=2,\n",
    "    excluded_model_types=['KNN'],\n",
    "    ag_args_fit={'num_cpus': 10, 'num_gpus': 0, 'memory_ratio': 0.8},\n",
    ")\n",
    "\n",
    "# Summarize results\n",
    "results = predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9874966-b996-47ee-933a-2d54565205a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_types': {'LightGBMXT_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L1': 'StackerEnsembleModel_LGB',\n",
       "  'WeightedEnsemble_L2': 'WeightedEnsembleModel',\n",
       "  'LightGBMXT_BAG_L2': 'StackerEnsembleModel_LGB',\n",
       "  'LightGBM_BAG_L2': 'StackerEnsembleModel_LGB',\n",
       "  'CatBoost_BAG_L2': 'StackerEnsembleModel_CatBoost',\n",
       "  'WeightedEnsemble_L3': 'WeightedEnsembleModel'},\n",
       " 'model_performance': {'LightGBMXT_BAG_L1': 0.9847572477816731,\n",
       "  'LightGBM_BAG_L1': 0.9832299831623279,\n",
       "  'WeightedEnsemble_L2': 0.9847572477816731,\n",
       "  'LightGBMXT_BAG_L2': 0.9841239565479641,\n",
       "  'LightGBM_BAG_L2': 0.9844662633193582,\n",
       "  'CatBoost_BAG_L2': 0.9844267058453176,\n",
       "  'WeightedEnsemble_L3': 0.9847375149920211},\n",
       " 'model_best': 'WeightedEnsemble_L2',\n",
       " 'model_paths': {'LightGBMXT_BAG_L1': ['LightGBMXT_BAG_L1'],\n",
       "  'LightGBM_BAG_L1': ['LightGBM_BAG_L1'],\n",
       "  'WeightedEnsemble_L2': ['WeightedEnsemble_L2'],\n",
       "  'LightGBMXT_BAG_L2': ['LightGBMXT_BAG_L2'],\n",
       "  'LightGBM_BAG_L2': ['LightGBM_BAG_L2'],\n",
       "  'CatBoost_BAG_L2': ['CatBoost_BAG_L2'],\n",
       "  'WeightedEnsemble_L3': ['WeightedEnsemble_L3']},\n",
       " 'model_fit_times': {'LightGBMXT_BAG_L1': 2164.584958076477,\n",
       "  'LightGBM_BAG_L1': 397.034631729126,\n",
       "  'WeightedEnsemble_L2': 10.486507415771484,\n",
       "  'LightGBMXT_BAG_L2': 819.2696211338043,\n",
       "  'LightGBM_BAG_L2': 102.03230810165405,\n",
       "  'CatBoost_BAG_L2': 30.70386505126953,\n",
       "  'WeightedEnsemble_L3': 26.09559178352356},\n",
       " 'model_pred_times': {'LightGBMXT_BAG_L1': 77.07902359962463,\n",
       "  'LightGBM_BAG_L1': 15.305299043655396,\n",
       "  'WeightedEnsemble_L2': 0.6716222763061523,\n",
       "  'LightGBMXT_BAG_L2': 28.493898391723633,\n",
       "  'LightGBM_BAG_L2': 1.572997808456421,\n",
       "  'CatBoost_BAG_L2': 0.4769928455352783,\n",
       "  'WeightedEnsemble_L3': 0.6851036548614502},\n",
       " 'num_bag_folds': 8,\n",
       " 'max_stack_level': 3,\n",
       " 'num_classes': 2,\n",
       " 'model_hyperparams': {'LightGBMXT_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_BAG_L1': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'WeightedEnsemble_L2': {'use_orig_features': False,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBMXT_BAG_L2': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'LightGBM_BAG_L2': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'CatBoost_BAG_L2': {'use_orig_features': True,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True},\n",
       "  'WeightedEnsemble_L3': {'use_orig_features': False,\n",
       "   'max_base_models': 25,\n",
       "   'max_base_models_per_type': 5,\n",
       "   'save_bag_folds': True}},\n",
       " 'leaderboard':                  model  score_val eval_metric  pred_time_val     fit_time  \\\n",
       " 0    LightGBMXT_BAG_L1   0.984757         mcc      77.079024  2164.584958   \n",
       " 1  WeightedEnsemble_L2   0.984757         mcc      77.750646  2175.071465   \n",
       " 2  WeightedEnsemble_L3   0.984738         mcc     123.613315  3539.720976   \n",
       " 3      LightGBM_BAG_L2   0.984466         mcc      93.957320  2663.651898   \n",
       " 4      CatBoost_BAG_L2   0.984427         mcc      92.861315  2592.323455   \n",
       " 5    LightGBMXT_BAG_L2   0.984124         mcc     120.878221  3380.889211   \n",
       " 6      LightGBM_BAG_L1   0.983230         mcc      15.305299   397.034632   \n",
       " \n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       " 0               77.079024        2164.584958            1       True   \n",
       " 1                0.671622          10.486507            2       True   \n",
       " 2                0.685104          26.095592            3       True   \n",
       " 3                1.572998         102.032308            2       True   \n",
       " 4                0.476993          30.703865            2       True   \n",
       " 5               28.493898         819.269621            2       True   \n",
       " 6               15.305299         397.034632            1       True   \n",
       " \n",
       "    fit_order  \n",
       " 0          1  \n",
       " 1          3  \n",
       " 2          7  \n",
       " 3          5  \n",
       " 4          6  \n",
       " 5          4  \n",
       " 6          2  }"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ead32d4-0e29-48f7-9859-d52237f639cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 model  score_val eval_metric  pred_time_val     fit_time  \\\n",
      "0    LightGBMXT_BAG_L1   0.984757         mcc      77.079024  2164.584958   \n",
      "1  WeightedEnsemble_L2   0.984757         mcc      77.750646  2175.071465   \n",
      "2  WeightedEnsemble_L3   0.984738         mcc     123.613315  3539.720976   \n",
      "3      LightGBM_BAG_L2   0.984466         mcc      93.957320  2663.651898   \n",
      "4      CatBoost_BAG_L2   0.984427         mcc      92.861315  2592.323455   \n",
      "5    LightGBMXT_BAG_L2   0.984124         mcc     120.878221  3380.889211   \n",
      "6      LightGBM_BAG_L1   0.983230         mcc      15.305299   397.034632   \n",
      "\n",
      "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0               77.079024        2164.584958            1       True   \n",
      "1                0.671622          10.486507            2       True   \n",
      "2                0.685104          26.095592            3       True   \n",
      "3                1.572998         102.032308            2       True   \n",
      "4                0.476993          30.703865            2       True   \n",
      "5               28.493898         819.269621            2       True   \n",
      "6               15.305299         397.034632            1       True   \n",
      "\n",
      "   fit_order  \n",
      "0          1  \n",
      "1          3  \n",
      "2          7  \n",
      "3          5  \n",
      "4          6  \n",
      "5          4  \n",
      "6          2  \n"
     ]
    }
   ],
   "source": [
    "# Get the leaderboard to see the performance of the models\n",
    "leaderboard = predictor.leaderboard(silent=True)\n",
    "\n",
    "# Print the leaderboard for reference\n",
    "print(leaderboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85108a24-5432-4b55-9d03-347ad846d1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>0.984757</td>\n",
       "      <td>mcc</td>\n",
       "      <td>77.079024</td>\n",
       "      <td>2164.584958</td>\n",
       "      <td>77.079024</td>\n",
       "      <td>2164.584958</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.984757</td>\n",
       "      <td>mcc</td>\n",
       "      <td>77.750646</td>\n",
       "      <td>2175.071465</td>\n",
       "      <td>0.671622</td>\n",
       "      <td>10.486507</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.984738</td>\n",
       "      <td>mcc</td>\n",
       "      <td>123.613315</td>\n",
       "      <td>3539.720976</td>\n",
       "      <td>0.685104</td>\n",
       "      <td>26.095592</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>0.984466</td>\n",
       "      <td>mcc</td>\n",
       "      <td>93.957320</td>\n",
       "      <td>2663.651898</td>\n",
       "      <td>1.572998</td>\n",
       "      <td>102.032308</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>0.984427</td>\n",
       "      <td>mcc</td>\n",
       "      <td>92.861315</td>\n",
       "      <td>2592.323455</td>\n",
       "      <td>0.476993</td>\n",
       "      <td>30.703865</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>0.984124</td>\n",
       "      <td>mcc</td>\n",
       "      <td>120.878221</td>\n",
       "      <td>3380.889211</td>\n",
       "      <td>28.493898</td>\n",
       "      <td>819.269621</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.983230</td>\n",
       "      <td>mcc</td>\n",
       "      <td>15.305299</td>\n",
       "      <td>397.034632</td>\n",
       "      <td>15.305299</td>\n",
       "      <td>397.034632</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  score_val eval_metric  pred_time_val     fit_time  \\\n",
       "0    LightGBMXT_BAG_L1   0.984757         mcc      77.079024  2164.584958   \n",
       "1  WeightedEnsemble_L2   0.984757         mcc      77.750646  2175.071465   \n",
       "2  WeightedEnsemble_L3   0.984738         mcc     123.613315  3539.720976   \n",
       "3      LightGBM_BAG_L2   0.984466         mcc      93.957320  2663.651898   \n",
       "4      CatBoost_BAG_L2   0.984427         mcc      92.861315  2592.323455   \n",
       "5    LightGBMXT_BAG_L2   0.984124         mcc     120.878221  3380.889211   \n",
       "6      LightGBM_BAG_L1   0.983230         mcc      15.305299   397.034632   \n",
       "\n",
       "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0               77.079024        2164.584958            1       True   \n",
       "1                0.671622          10.486507            2       True   \n",
       "2                0.685104          26.095592            3       True   \n",
       "3                1.572998         102.032308            2       True   \n",
       "4                0.476993          30.703865            2       True   \n",
       "5               28.493898         819.269621            2       True   \n",
       "6               15.305299         397.034632            1       True   \n",
       "\n",
       "   fit_order  \n",
       "0          1  \n",
       "1          3  \n",
       "2          7  \n",
       "3          5  \n",
       "4          6  \n",
       "5          4  \n",
       "6          2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bb296aa-fe34-4f21-bdba-4d369f3ba917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LightGBMXT_BAG_L1',\n",
       " 'WeightedEnsemble_L2',\n",
       " 'WeightedEnsemble_L3',\n",
       " 'LightGBM_BAG_L2',\n",
       " 'CatBoost_BAG_L2',\n",
       " 'LightGBMXT_BAG_L2',\n",
       " 'LightGBM_BAG_L1']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the top 10 models based on the leaderboard\n",
    "top_10_models = leaderboard['model'].head(10).tolist()\n",
    "top_10_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ebba9ef-a67a-4a05-8c12-0ce589354e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LightGBMXT_BAG_L1\n",
      "Hyperparameters:\n",
      "{'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}\n",
      "--------------------------------------------------\n",
      "Model: WeightedEnsemble_L2\n",
      "Hyperparameters:\n",
      "{'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}\n",
      "--------------------------------------------------\n",
      "Model: WeightedEnsemble_L3\n",
      "Hyperparameters:\n",
      "{'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}\n",
      "--------------------------------------------------\n",
      "Model: LightGBM_BAG_L2\n",
      "Hyperparameters:\n",
      "{'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}\n",
      "--------------------------------------------------\n",
      "Model: CatBoost_BAG_L2\n",
      "Hyperparameters:\n",
      "{'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}\n",
      "--------------------------------------------------\n",
      "Model: LightGBMXT_BAG_L2\n",
      "Hyperparameters:\n",
      "{'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}\n",
      "--------------------------------------------------\n",
      "Model: LightGBM_BAG_L1\n",
      "Hyperparameters:\n",
      "{'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the top 10 models and print their hyperparameters\n",
    "for model in top_10_models:\n",
    "    hyperparameters = predictor.info()['model_info'][model]['hyperparameters']\n",
    "    print(f\"Model: {model}\")\n",
    "    print(\"Hyperparameters:\")\n",
    "    print(hyperparameters)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1538c27e-4539-4792-9040-5453651b0011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "y_pred = predictor.predict(test_df)\n",
    "\n",
    "# Create the submission file\n",
    "sub = pd.read_csv('test.csv')\n",
    "sub['class'] = y_pred\n",
    "sub.to_csv('Submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae16f3ea-9768-4505-b0ec-40171d032cc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StackerEnsembleModel' object has no attribute 'preprocess_pipeline'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m model_name \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mget_model_best()  \u001b[38;5;66;03m# or any model name\u001b[39;00m\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mload_model(model_name)\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess_pipeline\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'StackerEnsembleModel' object has no attribute 'preprocess_pipeline'"
     ]
    }
   ],
   "source": [
    "trainer = predictor._trainer\n",
    "\n",
    "# Example: Get preprocessing for a specific model\n",
    "model_name = trainer.get_model_best()  # or any model name\n",
    "model = trainer.load_model(model_name)\n",
    "print(model.preprocess_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "071425e6-25ee-40c6-b823-38b9f73c4b87",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AutoTrainer' object has no attribute 'preprocessor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessor\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'AutoTrainer' object has no attribute 'preprocessor'"
     ]
    }
   ],
   "source": [
    "print(trainer.preprocessor)  # This might give you details about the preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26e6dcf8-0ce1-4d51-abea-11e2b297b4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LightGBMXT_BAG_L1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'StackerEnsembleModel' object has no attribute 'preprocess_pipeline'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mload_model(model_name)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess_pipeline\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'StackerEnsembleModel' object has no attribute 'preprocess_pipeline'"
     ]
    }
   ],
   "source": [
    "for model_name in trainer.get_model_names():\n",
    "    model = trainer.load_model(model_name)\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(model.preprocess_pipeline)  # This might work for individual models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff17041f-da89-4d61-993a-3d53bb95511a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slotnames__', '__str__', '__subclasshook__', '__weakref__', '_add_child_times_to_bag', '_add_parallel_child_times', '_add_predict_n_size', '_add_stack_to_feature_metadata', '_ag_params', '_apply_conformalization', '_apply_temperature_scaling', '_bagged_mode', '_base_model_performances_dict', '_base_model_types_inner_dict', '_calculate_total_resources', '_child_oof', '_child_type', '_class_tags', '_compile', '_compiler', '_compute_fit_metadata', '_compute_permutation_importance', '_construct_empty_oof', '_convert_proba_to_unified_form', '_cv_splitters', '_default_compiler', '_estimate_memory_usage', '_feature_metadata', '_features', '_features_internal', '_fit', '_fit_folds', '_fit_metadata', '_fit_single', '_generate_fold_configs', '_get_ag_params', '_get_child_aux_val', '_get_child_info', '_get_child_model_names', '_get_class_tags', '_get_compiler', '_get_compressed_params', '_get_compressed_params_trained', '_get_cv_splitter', '_get_default_ag_args', '_get_default_ag_args_ensemble', '_get_default_auxiliary_params', '_get_default_fold_fitting_strategy', '_get_default_hpo_executor', '_get_default_resources', '_get_default_searchspace', '_get_default_stopping_metric', '_get_fold_fitting_strategy', '_get_hpo_backend', '_get_input_types', '_get_maximum_resources', '_get_memory_size', '_get_model_base', '_get_model_params', '_get_params', '_get_search_space', '_get_tags', '_get_tags_child', '_hyperparameter_tune', '_init_misc', '_init_params', '_init_params_aux', '_init_user_params', '_initialize', '_is_features_in_same_as_ex', '_is_fit_metadata_registered', '_is_initialized', '_k', '_k_fold_end', '_k_per_n_repeat', '_load_oof', '_model_names', '_more_tags', '_n_repeats', '_n_repeats_finished', '_oof_filename', '_oof_pred_model_repeats', '_oof_pred_proba', '_params_aux_child', '_path_v2', '_post_fit', '_predict_n_size', '_predict_n_size_lst', '_predict_proba', '_predict_proba_internal', '_predict_proba_oof', '_preprocess', '_preprocess_fit_args', '_preprocess_fit_resources', '_preprocess_nonadaptive', '_preprocess_set_features', '_process_user_provided_resource_requirement_to_calculate_total_resource_when_ensemble', '_random_state', '_register_fit_metadata', '_set_default_auxiliary_params', '_set_default_param_value', '_set_default_params', '_set_n_repeat_single', '_update_k_fold', '_user_params', '_user_params_aux', '_valid_compilers', '_validate_bag_kwargs', '_validate_fit_memory_usage', '_validate_fit_resources', 'add_child', 'base_model_names', 'base_model_paths_dict', 'base_model_types_dict', 'base_models_dict', 'can_compile', 'can_fit', 'can_infer', 'can_predict_proba', 'compile', 'compile_time', 'compute_feature_importance', 'conformalize', 'convert_to_refit_full_template', 'convert_to_refit_full_template_child', 'convert_to_refit_full_via_copy', 'convert_to_template', 'convert_to_template_child', 'create_contexts', 'delete_from_disk', 'disk_usage', 'estimate_memory_usage', 'eval_metric', 'feature_metadata', 'features', 'fit', 'fit_time', 'get_compiler_name', 'get_features', 'get_fit_metadata', 'get_info', 'get_memory_size', 'get_minimum_resources', 'get_params', 'get_trained_params', 'hyperparameter_tune', 'initialize', 'is_fit', 'is_initialized', 'is_stratified', 'is_valid', 'is_valid_oof', 'limit_models', 'limit_models_per_type', 'load', 'load_base_model', 'load_child', 'load_info', 'load_model_base', 'load_oof', 'low_memory', 'model', 'model_base', 'model_file_name', 'model_info_json_name', 'model_info_name', 'models', 'n_children', 'name', 'nondefault_params', 'normalize_pred_probas', 'num_classes', 'num_pred_cols_per_model', 'params', 'params_aux', 'params_trained', 'path', 'path_root', 'path_suffix', 'persist_child_models', 'pred_probas_to_df', 'predict', 'predict_1_time', 'predict_children', 'predict_from_proba', 'predict_n_size', 'predict_n_time_per_row', 'predict_proba', 'predict_proba_children', 'predict_proba_oof', 'predict_time', 'preprocess', 'problem_type', 'quantile_levels', 'record_predict_info', 'reduce_memory_size', 'rename', 'reset_metrics', 'save', 'save_child', 'save_info', 'save_model_base', 'score', 'score_with_oof', 'score_with_y_pred_proba', 'set_contexts', 'set_stack_columns', 'stack_column_prefix_lst', 'stack_column_prefix_to_model_map', 'stack_columns', 'stopping_metric', 'unpersist_child_models', 'val_score', 'validate_fit_resources']\n"
     ]
    }
   ],
   "source": [
    "print(dir(model))  # List all attributes and methods of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66300532-994f-4559-85c5-0f79ddcb6793",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AutoTrainer' object has no attribute 'load_data_internal'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m preprocessed_data \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data_internal\u001b[49m(train_data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(preprocessed_data\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'AutoTrainer' object has no attribute 'load_data_internal'"
     ]
    }
   ],
   "source": [
    "preprocessed_data = trainer.load_data_internal(train_data=True)\n",
    "print(preprocessed_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8354b30a-4186-4f41-a24b-3c50b93c40b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'LightGBMXT_BAG_L1', 'model_type': 'StackerEnsembleModel', 'problem_type': 'binary', 'eval_metric': 'mcc', 'stopping_metric': 'mcc', 'fit_time': 2164.584958076477, 'num_classes': 2, 'quantile_levels': None, 'predict_time': 77.07902359962463, 'val_score': 0.9847572477816731, 'hyperparameters': {'use_orig_features': True, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'hyperparameters_fit': {}, 'hyperparameters_nondefault': [], 'ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}, 'num_features': 20, 'features': ['cap-color', 'ring-type', 'gill-color', 'veil-type', 'stem-surface', 'stem-height', 'cap-shape', 'spore-print-color', 'habitat', 'stem-color', 'veil-color', 'has-ring', 'gill-attachment', 'season', 'does-bruise-or-bleed', 'stem-root', 'cap-surface', 'gill-spacing', 'stem-width', 'cap-diameter'], 'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata object at 0x000001B3F2B5CAF0>, 'memory_size': 3141, 'compile_time': None, 'is_initialized': True, 'is_fit': True, 'is_valid': True, 'can_infer': True, 'bagged_info': {'child_model_type': 'LGBModel', 'num_child_models': 8, 'child_model_names': ['S1F1', 'S1F2', 'S1F3', 'S1F4', 'S1F5', 'S1F6', 'S1F8', 'S1F7'], '_n_repeats': 1, '_k_per_n_repeat': [8], '_random_state': 1, 'low_memory': True, 'bagged_mode': True, 'max_memory_size': 67719808, 'min_memory_size': 9560509, 'child_hyperparameters': {'learning_rate': 0.05, 'extra_trees': True}, 'child_hyperparameters_fit': {'num_boost_round': 2496}, 'child_ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 10, 'num_gpus': 0, 'memory_ratio': 0.8}}, 'stacker_info': {'num_base_models': 0, 'base_model_names': []}, 'children_info': {'S1F1': {'name': 'S1F1', 'model_type': 'LGBModel', 'problem_type': 'binary', 'eval_metric': 'mcc', 'stopping_metric': 'mcc', 'fit_time': 531.6741003990173, 'num_classes': 2, 'quantile_levels': None, 'predict_time': 9.322474956512451, 'val_score': 0.9849191606778643, 'hyperparameters': {'learning_rate': 0.05, 'extra_trees': True}, 'hyperparameters_fit': {'num_boost_round': 2148}, 'hyperparameters_nondefault': ['extra_trees'], 'ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 10, 'num_gpus': 0, 'memory_ratio': 0.8}, 'num_features': 20, 'features': ['cap-diameter', 'stem-height', 'stem-width', 'cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color', 'stem-root', 'stem-surface', 'stem-color', 'veil-type', 'veil-color', 'has-ring', 'ring-type', 'spore-print-color', 'habitat', 'season'], 'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata object at 0x000001B3F2DECB20>, 'memory_size': 7289576, 'compile_time': None, 'is_initialized': True, 'is_fit': True, 'is_valid': True, 'can_infer': True}, 'S1F2': {'name': 'S1F2', 'model_type': 'LGBModel', 'problem_type': 'binary', 'eval_metric': 'mcc', 'stopping_metric': 'mcc', 'fit_time': 531.8322398662567, 'num_classes': 2, 'quantile_levels': None, 'predict_time': 10.646145820617676, 'val_score': 0.9848305397081656, 'hyperparameters': {'learning_rate': 0.05, 'extra_trees': True}, 'hyperparameters_fit': {'num_boost_round': 2750}, 'hyperparameters_nondefault': ['extra_trees'], 'ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 10, 'num_gpus': 0, 'memory_ratio': 0.8}, 'num_features': 20, 'features': ['cap-diameter', 'stem-height', 'stem-width', 'cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color', 'stem-root', 'stem-surface', 'stem-color', 'veil-type', 'veil-color', 'has-ring', 'ring-type', 'spore-print-color', 'habitat', 'season'], 'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata object at 0x000001B3F2AE49D0>, 'memory_size': 9313601, 'compile_time': None, 'is_initialized': True, 'is_fit': True, 'is_valid': True, 'can_infer': True}, 'S1F3': {'name': 'S1F3', 'model_type': 'LGBModel', 'problem_type': 'binary', 'eval_metric': 'mcc', 'stopping_metric': 'mcc', 'fit_time': 531.8523738384247, 'num_classes': 2, 'quantile_levels': None, 'predict_time': 11.366375207901001, 'val_score': 0.9846329919098575, 'hyperparameters': {'learning_rate': 0.05, 'extra_trees': True}, 'hyperparameters_fit': {'num_boost_round': 2766}, 'hyperparameters_nondefault': ['extra_trees'], 'ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 10, 'num_gpus': 0, 'memory_ratio': 0.8}, 'num_features': 20, 'features': ['cap-diameter', 'stem-height', 'stem-width', 'cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color', 'stem-root', 'stem-surface', 'stem-color', 'veil-type', 'veil-color', 'has-ring', 'ring-type', 'spore-print-color', 'habitat', 'season'], 'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata object at 0x000001B3F2990820>, 'memory_size': 9384357, 'compile_time': None, 'is_initialized': True, 'is_fit': True, 'is_valid': True, 'can_infer': True}, 'S1F4': {'name': 'S1F4', 'model_type': 'LGBModel', 'problem_type': 'binary', 'eval_metric': 'mcc', 'stopping_metric': 'mcc', 'fit_time': 531.9805383682251, 'num_classes': 2, 'quantile_levels': None, 'predict_time': 10.18023157119751, 'val_score': 0.984881025707304, 'hyperparameters': {'learning_rate': 0.05, 'extra_trees': True}, 'hyperparameters_fit': {'num_boost_round': 2657}, 'hyperparameters_nondefault': ['extra_trees'], 'ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 10, 'num_gpus': 0, 'memory_ratio': 0.8}, 'num_features': 20, 'features': ['cap-diameter', 'stem-height', 'stem-width', 'cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color', 'stem-root', 'stem-surface', 'stem-color', 'veil-type', 'veil-color', 'has-ring', 'ring-type', 'spore-print-color', 'habitat', 'season'], 'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata object at 0x000001B3F281C550>, 'memory_size': 9018741, 'compile_time': None, 'is_initialized': True, 'is_fit': True, 'is_valid': True, 'can_infer': True}, 'S1F5': {'name': 'S1F5', 'model_type': 'LGBModel', 'problem_type': 'binary', 'eval_metric': 'mcc', 'stopping_metric': 'mcc', 'fit_time': 531.7053942680359, 'num_classes': 2, 'quantile_levels': None, 'predict_time': 11.457090616226196, 'val_score': 0.9846037280490152, 'hyperparameters': {'learning_rate': 0.05, 'extra_trees': True}, 'hyperparameters_fit': {'num_boost_round': 2722}, 'hyperparameters_nondefault': ['extra_trees'], 'ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 10, 'num_gpus': 0, 'memory_ratio': 0.8}, 'num_features': 20, 'features': ['cap-diameter', 'stem-height', 'stem-width', 'cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color', 'stem-root', 'stem-surface', 'stem-color', 'veil-type', 'veil-color', 'has-ring', 'ring-type', 'spore-print-color', 'habitat', 'season'], 'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata object at 0x000001B3F2A1BD90>, 'memory_size': 9214017, 'compile_time': None, 'is_initialized': True, 'is_fit': True, 'is_valid': True, 'can_infer': True}, 'S1F6': {'name': 'S1F6', 'model_type': 'LGBModel', 'problem_type': 'binary', 'eval_metric': 'mcc', 'stopping_metric': 'mcc', 'fit_time': 531.8502156734467, 'num_classes': 2, 'quantile_levels': None, 'predict_time': 11.652012825012207, 'val_score': 0.9847582993081985, 'hyperparameters': {'learning_rate': 0.05, 'extra_trees': True}, 'hyperparameters_fit': {'num_boost_round': 2824}, 'hyperparameters_nondefault': ['extra_trees'], 'ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 10, 'num_gpus': 0, 'memory_ratio': 0.8}, 'num_features': 20, 'features': ['cap-diameter', 'stem-height', 'stem-width', 'cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color', 'stem-root', 'stem-surface', 'stem-color', 'veil-type', 'veil-color', 'has-ring', 'ring-type', 'spore-print-color', 'habitat', 'season'], 'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata object at 0x000001B3F2E1C2B0>, 'memory_size': 9557368, 'compile_time': None, 'is_initialized': True, 'is_fit': True, 'is_valid': True, 'can_infer': True}, 'S1F8': {'name': 'S1F8', 'model_type': 'LGBModel', 'problem_type': 'binary', 'eval_metric': 'mcc', 'stopping_metric': 'mcc', 'fit_time': 392.5502083301544, 'num_classes': 2, 'quantile_levels': None, 'predict_time': 5.299427270889282, 'val_score': 0.9845767374440165, 'hyperparameters': {'learning_rate': 0.05, 'extra_trees': True}, 'hyperparameters_fit': {'num_boost_round': 1532}, 'hyperparameters_nondefault': ['extra_trees'], 'ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 10, 'num_gpus': 0, 'memory_ratio': 0.8}, 'num_features': 20, 'features': ['cap-diameter', 'stem-height', 'stem-width', 'cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color', 'stem-root', 'stem-surface', 'stem-color', 'veil-type', 'veil-color', 'has-ring', 'ring-type', 'spore-print-color', 'habitat', 'season'], 'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata object at 0x000001B3F2E1CFA0>, 'memory_size': 5216297, 'compile_time': None, 'is_initialized': True, 'is_fit': True, 'is_valid': True, 'can_infer': True}, 'S1F7': {'name': 'S1F7', 'model_type': 'LGBModel', 'problem_type': 'binary', 'eval_metric': 'mcc', 'stopping_metric': 'mcc', 'fit_time': 531.6167085170746, 'num_classes': 2, 'quantile_levels': None, 'predict_time': 7.1552653312683105, 'val_score': 0.9848556608335842, 'hyperparameters': {'learning_rate': 0.05, 'extra_trees': True}, 'hyperparameters_fit': {'num_boost_round': 2569}, 'hyperparameters_nondefault': ['extra_trees'], 'ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': ['bool', 'int', 'float', 'category'], 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'num_cpus': 10, 'num_gpus': 0, 'memory_ratio': 0.8}, 'num_features': 20, 'features': ['cap-diameter', 'stem-height', 'stem-width', 'cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', 'gill-spacing', 'gill-color', 'stem-root', 'stem-surface', 'stem-color', 'veil-type', 'veil-color', 'has-ring', 'ring-type', 'spore-print-color', 'habitat', 'season'], 'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata object at 0x000001B3F2B2F940>, 'memory_size': 8722710, 'compile_time': None, 'is_initialized': True, 'is_fit': True, 'is_valid': True, 'can_infer': True}}}\n"
     ]
    }
   ],
   "source": [
    "model_info = model.get_info()\n",
    "print(model_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44469bd9-56be-45d2-a3fd-b06942d7f65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features used by the best model: ['LightGBMXT_BAG_L1', 'LightGBM_BAG_L1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hi\\AppData\\Local\\Temp\\ipykernel_12916\\1474894070.py:1: DeprecationWarning: `get_model_best` has been deprecated and will be removed in version 1.2. Please use `model_best` instead. This will raise an error in the future!\n",
      "  best_model_name = predictor.get_model_best()\n"
     ]
    }
   ],
   "source": [
    "best_model_name = predictor.get_model_best()\n",
    "best_model = predictor._trainer.load_model(best_model_name)\n",
    "\n",
    "# Get the features used by the model\n",
    "features = best_model.features\n",
    "print(\"Features used by the best model:\", features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7626846-e430-4b4f-80b2-0885f05c0ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameters of the best model: {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}\n"
     ]
    }
   ],
   "source": [
    "# Get the hyperparameters of the best model\n",
    "hyperparameters = best_model.params\n",
    "print(\"Hyperparameters of the best model:\", hyperparameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ff2e7cb-c505-476b-967b-fb51ee411dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing steps applied: <bound method StackerEnsembleModel.preprocess of <autogluon.core.models.ensemble.weighted_ensemble_model.WeightedEnsembleModel object at 0x000001B3F2B2BCA0>>\n"
     ]
    }
   ],
   "source": [
    "# Access the preprocessing steps\n",
    "preprocessing = best_model.preprocess\n",
    "print(\"Preprocessing steps applied:\", preprocessing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "297d936b-fcf3-48f1-9e7f-8e9c097835cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detailed model info: {'name': 'WeightedEnsemble_L2', 'model_type': 'WeightedEnsembleModel', 'problem_type': 'binary', 'eval_metric': 'mcc', 'stopping_metric': 'mcc', 'fit_time': 10.486507415771484, 'num_classes': 2, 'quantile_levels': None, 'predict_time': 0.6716222763061523, 'val_score': 0.9847572477816731, 'hyperparameters': {'use_orig_features': False, 'max_base_models': 25, 'max_base_models_per_type': 5, 'save_bag_folds': True}, 'hyperparameters_fit': {}, 'hyperparameters_nondefault': ['save_bag_folds'], 'ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}, 'num_features': 1, 'features': ['LightGBMXT_BAG_L1'], 'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata object at 0x000001B3F2B5C970>, 'memory_size': 2826, 'compile_time': None, 'is_initialized': True, 'is_fit': True, 'is_valid': True, 'can_infer': True, 'bagged_info': {'child_model_type': 'GreedyWeightedEnsembleModel', 'num_child_models': 1, 'child_model_names': ['S1F1'], '_n_repeats': 1, '_k_per_n_repeat': [1], '_random_state': 2, 'low_memory': False, 'bagged_mode': False, 'max_memory_size': 2826, 'min_memory_size': 2826, 'child_hyperparameters': {'ensemble_size': 25, 'subsample_size': 1000000}, 'child_hyperparameters_fit': {'ensemble_size': 1}, 'child_ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}}, 'stacker_info': {'num_base_models': 1, 'base_model_names': ['LightGBMXT_BAG_L1']}, 'children_info': {'S1F1': {'name': 'S1F1', 'model_type': 'GreedyWeightedEnsembleModel', 'problem_type': 'binary', 'eval_metric': 'mcc', 'stopping_metric': 'mcc', 'fit_time': 10.486507415771484, 'num_classes': 2, 'quantile_levels': None, 'predict_time': None, 'val_score': None, 'hyperparameters': {'ensemble_size': 25, 'subsample_size': 1000000}, 'hyperparameters_fit': {'ensemble_size': 1}, 'hyperparameters_nondefault': [], 'ag_args_fit': {'max_memory_usage_ratio': 1.0, 'max_time_limit_ratio': 1.0, 'max_time_limit': None, 'min_time_limit': 0, 'valid_raw_types': None, 'valid_special_types': None, 'ignored_type_group_special': None, 'ignored_type_group_raw': None, 'get_features_kwargs': None, 'get_features_kwargs_extra': None, 'predict_1_batch_size': None, 'temperature_scalar': None, 'drop_unique': False}, 'num_features': 1, 'features': ['LightGBMXT_BAG_L1'], 'feature_metadata': <autogluon.common.features.feature_metadata.FeatureMetadata object at 0x000001B411B81670>, 'memory_size': 5013, 'compile_time': None, 'is_initialized': True, 'is_fit': True, 'is_valid': True, 'can_infer': True, 'model_weights': {'LightGBMXT_BAG_L1': 1.0}}}}\n"
     ]
    }
   ],
   "source": [
    "model_info = best_model.get_info()\n",
    "print(\"Detailed model info:\", model_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f997e7-2028-4ce3-a9c3-f9e94e25e777",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
