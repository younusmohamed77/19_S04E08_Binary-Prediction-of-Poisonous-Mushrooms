{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ef49187-d485-4279-be4c-758c77b9cbfe",
   "metadata": {},
   "source": [
    "# Kaggle Playground - Season 4 Episode \n",
    "## Binary Classification of Insurance Cross Selling\n",
    "\n",
    "Competion link - https://www.kaggle.com/competitions/playground-series-s4e8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325c5446-7bde-481e-b86f-b56d636cb91f",
   "metadata": {},
   "source": [
    "### Steps\n",
    "- Import the necessary libraries, packages and modules\n",
    "- Read the datsets as data framers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f39078c-9c75-4583-9df7-33ea4522274e",
   "metadata": {},
   "source": [
    "### Understand the problem\n",
    "\n",
    "- class is the target variable\n",
    "- It determines the class of a mushroom depending on the given variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "dfbb41e6-7354-42fc-9612-4c3138b7833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries, packages and modules\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import dtale    # Use of a web progrm to analysis the data deeply\n",
    "import lightgbm as lgb\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optuna\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "# import statsmodels.api as sm\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import xgboost as xgb\n",
    "# import zipfile\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from optuna.samplers import TPESampler\n",
    "#from pandas_profiling import ProfileReport\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.ensemble import (BaggingClassifier, RandomForestClassifier, AdaBoostClassifier,\n",
    "                              GradientBoostingClassifier, HistGradientBoostingClassifier)\n",
    "from sklearn.feature_selection import chi2, RFE, SelectKBest, SelectFromModel  \n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, make_scorer, matthews_corrcoef, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# from skopt import BayesSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a6bdb543-c63a-404d-a543-cccea02eb51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# Test to see if TensorFlow can utilize the GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "dcd0b9bd-a539-4585-8adb-9c0294737c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Train data load completed. Time elapsed: 4.28 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stem-root</th>\n",
       "      <th>stem-surface</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>e</td>\n",
       "      <td>8.80</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "      <td>f</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>w</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>p</td>\n",
       "      <td>4.51</td>\n",
       "      <td>x</td>\n",
       "      <td>h</td>\n",
       "      <td>o</td>\n",
       "      <td>f</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>o</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id class  cap-diameter cap-shape cap-surface cap-color  \\\n",
       "0   0     e          8.80         f           s         u   \n",
       "1   1     p          4.51         x           h         o   \n",
       "\n",
       "  does-bruise-or-bleed gill-attachment gill-spacing gill-color  ...  \\\n",
       "0                    f               a            c          w  ...   \n",
       "1                    f               a            c          n  ...   \n",
       "\n",
       "   stem-root  stem-surface stem-color veil-type veil-color has-ring ring-type  \\\n",
       "0        NaN           NaN          w       NaN        NaN        f         f   \n",
       "1        NaN             y          o       NaN        NaN        t         z   \n",
       "\n",
       "  spore-print-color habitat season  \n",
       "0               NaN       d      a  \n",
       "1               NaN       d      w  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "logger.info(f\"Train data load completed. Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "5eb23a83-e76a-4470-bf5f-323220940f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>...</th>\n",
       "      <th>stem-root</th>\n",
       "      <th>stem-surface</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3116945</td>\n",
       "      <td>8.64</td>\n",
       "      <td>x</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>11.13</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>u</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3116946</td>\n",
       "      <td>6.90</td>\n",
       "      <td>o</td>\n",
       "      <td>t</td>\n",
       "      <td>o</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c</td>\n",
       "      <td>y</td>\n",
       "      <td>1.27</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  cap-diameter cap-shape cap-surface cap-color does-bruise-or-bleed  \\\n",
       "0  3116945          8.64         x         NaN         n                    t   \n",
       "1  3116946          6.90         o           t         o                    f   \n",
       "\n",
       "  gill-attachment gill-spacing gill-color  stem-height  ...  stem-root  \\\n",
       "0             NaN          NaN          w        11.13  ...          b   \n",
       "1             NaN            c          y         1.27  ...        NaN   \n",
       "\n",
       "  stem-surface stem-color veil-type veil-color has-ring ring-type  \\\n",
       "0          NaN          w         u          w        t         g   \n",
       "1          NaN          n       NaN        NaN        f         f   \n",
       "\n",
       "  spore-print-color habitat season  \n",
       "0               NaN       d      a  \n",
       "1               NaN       d      a  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155c0975-bbdb-4768-9d61-f43a63f3f896",
   "metadata": {},
   "source": [
    "### Identify the target variable and features\n",
    "\n",
    "- class is the target variable\n",
    "- It determines the class of a mushroom depending on the given variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe796aa6-4445-4caa-b1ed-27058ee4fc02",
   "metadata": {},
   "source": [
    "### Remove duplicate rows\n",
    "\n",
    "- Checked the sum of duplicated rows in train and test datasets\n",
    "- No dupllicated rows in train dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06726f9b-0aa0-41e8-893d-8d6b226d879f",
   "metadata": {},
   "source": [
    "### Handling missing values\n",
    "\n",
    "- Checked the missing values in column\n",
    "- There are considerable amount of missing values in many columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "256fb363-6e4f-427d-9985-8626d461812f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3116945, 22)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0b7d55b1-a95b-47a0-bdba-4e7d0574a75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2077964, 21)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "22039987-da08-474d-a2d8-1fde55db683f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Train test split completed. Time elapsed: 6.58 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stem-root</th>\n",
       "      <th>stem-surface</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2419543</th>\n",
       "      <td>2419543</td>\n",
       "      <td>e</td>\n",
       "      <td>7.10</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910367</th>\n",
       "      <td>910367</td>\n",
       "      <td>p</td>\n",
       "      <td>7.11</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>f</td>\n",
       "      <td>x</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id class  cap-diameter cap-shape cap-surface cap-color  \\\n",
       "2419543  2419543     e          7.10         s           s         o   \n",
       "910367    910367     p          7.11         f         NaN         y   \n",
       "\n",
       "        does-bruise-or-bleed gill-attachment gill-spacing gill-color  ...  \\\n",
       "2419543                    f               d            d          b  ...   \n",
       "910367                     f               x            c          n  ...   \n",
       "\n",
       "         stem-root  stem-surface stem-color veil-type veil-color has-ring  \\\n",
       "2419543        NaN           NaN          w       NaN        NaN        f   \n",
       "910367         NaN           NaN          w       NaN        NaN        f   \n",
       "\n",
       "        ring-type spore-print-color habitat season  \n",
       "2419543         f               NaN       g      w  \n",
       "910367          f               NaN       d      a  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since we have only one data set, spliting it into train and test (validation)\n",
    "\n",
    "train_df_split, validation_df = train_test_split(train_df, train_size = 0.75, random_state = 42, stratify = train_df['class'])\n",
    "logger.info(f\"Train test split completed. Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "train_df_split.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644ced18-8b14-4857-b690-292a15d5c530",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "- Droping columns with more than 50% missing values\n",
    "- Using simple imputer\n",
    "- Encoding Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "9ae1569d-6023-41a2-9521-0f9780e4a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with extremely high missing values\n",
    "columns_to_drop = ['id', 'veil-type', 'spore-print-color', 'stem-root', 'veil-color', 'stem-surface']\n",
    "train_df_split.drop(columns=columns_to_drop, inplace=True)\n",
    "validation_df.drop(columns=columns_to_drop, inplace=True)\n",
    "test_df.drop(columns=columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "35ff6836-6a55-4025-a7e4-b26e55cb208d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>stem-width</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2419543</th>\n",
       "      <td>7.10</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>d</td>\n",
       "      <td>b</td>\n",
       "      <td>6.28</td>\n",
       "      <td>12.75</td>\n",
       "      <td>w</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910367</th>\n",
       "      <td>7.11</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>y</td>\n",
       "      <td>f</td>\n",
       "      <td>x</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>6.64</td>\n",
       "      <td>10.39</td>\n",
       "      <td>w</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>d</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cap-diameter cap-shape cap-surface cap-color does-bruise-or-bleed  \\\n",
       "2419543          7.10         s           s         o                    f   \n",
       "910367           7.11         f         NaN         y                    f   \n",
       "\n",
       "        gill-attachment gill-spacing gill-color  stem-height  stem-width  \\\n",
       "2419543               d            d          b         6.28       12.75   \n",
       "910367                x            c          n         6.64       10.39   \n",
       "\n",
       "        stem-color has-ring ring-type habitat season  \n",
       "2419543          w        f         f       g      w  \n",
       "910367           w        f         f       d      a  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spliting dependent and independent valriable\n",
    "\n",
    "y_train = train_df_split['class']\n",
    "train_df_split = train_df_split.drop('class', axis = 1)\n",
    "\n",
    "y_val = validation_df['class']\n",
    "validation_df = validation_df.drop('class', axis = 1)\n",
    "\n",
    "train_df_split.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "4a572d25-9449-4679-a3fa-0bd06c7f695c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Value is each categorical column :\n",
      "cap-shape 74\n",
      "Unique Value is each categorical column :\n",
      "cap-surface 83\n",
      "Unique Value is each categorical column :\n",
      "cap-color 78\n",
      "Unique Value is each categorical column :\n",
      "does-bruise-or-bleed 26\n",
      "Unique Value is each categorical column :\n",
      "gill-attachment 78\n",
      "Unique Value is each categorical column :\n",
      "gill-spacing 48\n",
      "Unique Value is each categorical column :\n",
      "gill-color 63\n",
      "Unique Value is each categorical column :\n",
      "stem-color 59\n",
      "Unique Value is each categorical column :\n",
      "has-ring 23\n",
      "Unique Value is each categorical column :\n",
      "ring-type 40\n",
      "Unique Value is each categorical column :\n",
      "habitat 52\n",
      "Unique Value is each categorical column :\n",
      "season 4\n"
     ]
    }
   ],
   "source": [
    "# Identify numerical and categorical columns\n",
    "numerical_cols = train_df_split.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = train_df_split.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(\"Unique Value is each categorical column :\")\n",
    "    print(col, train_df[col].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "a9b284d8-c741-4787-8e04-8db89cf00e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Missing values and categorical columns treatment completed. Time elapsed: 15.58 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed Training Data Shape: (2337708, 15)\n",
      "Transformed Validation Data Shape: (779237, 15)\n",
      "Transformed Test Data Shape: (2077964, 15)\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "# Define the imputer and scaler for numerical columns (median imputation and standard scaling)\n",
    "def preprocess_numerical_data(X, numerical_cols):\n",
    "    # Impute missing values with median\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_numerical_imputed = imputer.fit_transform(X[numerical_cols])\n",
    "    \n",
    "    # Scale the numerical data\n",
    "    scaler = StandardScaler()\n",
    "    X_numerical_scaled = scaler.fit_transform(X_numerical_imputed)\n",
    "    \n",
    "    return pd.DataFrame(X_numerical_scaled, columns=numerical_cols)\n",
    "\n",
    "# Define a function to apply LabelEncoder to each categorical column\n",
    "def encode_labels(df, columns):\n",
    "    df_encoded = df.copy()\n",
    "    le_dict = {}\n",
    "    for col in columns:\n",
    "        le = LabelEncoder()\n",
    "        df_encoded[col] = le.fit_transform(df_encoded[col])\n",
    "        le_dict[col] = le\n",
    "    return df_encoded, le_dict\n",
    "\n",
    "# Define the function to transform categorical columns using LabelEncoder\n",
    "def encode_labels_transform(X, categorical_cols):\n",
    "    df = pd.DataFrame(X, columns=categorical_cols)\n",
    "    df_encoded, _ = encode_labels(df, categorical_cols)\n",
    "    return df_encoded.values\n",
    "\n",
    "# Define the function to preprocess the data\n",
    "def preprocess_data(X, numerical_cols, categorical_cols):\n",
    "    # Transform numerical columns\n",
    "    num_transformed = preprocess_numerical_data(X, numerical_cols)\n",
    "    \n",
    "    # Transform categorical columns\n",
    "    cat_transformed = encode_labels_transform(X, categorical_cols)\n",
    "    \n",
    "    # Combine transformed numerical and categorical columns\n",
    "    X_transformed = pd.concat([num_transformed, pd.DataFrame(cat_transformed, columns=categorical_cols)], axis=1)\n",
    "    return X_transformed\n",
    "\n",
    "# Assuming you have your train and test dataframes\n",
    "train_df_transformed = preprocess_data(train_df_split, numerical_cols, categorical_cols)\n",
    "validation_df_transformed = preprocess_data(validation_df, numerical_cols, categorical_cols)\n",
    "test_df_transformed = preprocess_data(test_df, numerical_cols, categorical_cols)\n",
    "\n",
    "print(\"Transformed Training Data Shape:\", train_df_transformed.shape)\n",
    "print(\"Transformed Validation Data Shape:\", validation_df_transformed.shape)\n",
    "print(\"Transformed Test Data Shape:\", test_df_transformed.shape)\n",
    "\n",
    "logger.info(f\"Missing values and categorical columns treatment completed. Time elapsed: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "bd8136a7-a097-4926-a64c-39910521f1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the training labels\n",
    "label_encoder.fit(y_train)\n",
    "\n",
    "# Transform the labels for training and validation datasets\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_val = label_encoder.transform(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "e4755d28-7161-4d0d-9fbe-520a91a0c4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine feature names\n",
    "all_feature_names = numerical_cols.tolist() + categorical_cols.tolist()\n",
    "\n",
    "# Convert to DataFrame\n",
    "train_df_transformed = pd.DataFrame(train_df_transformed, columns=all_feature_names)\n",
    "validation_df_transformed = pd.DataFrame(validation_df_transformed, columns=all_feature_names)\n",
    "test_df_transformed = pd.DataFrame(test_df_transformed, columns=all_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b6dca119-07c8-4096-8169-c674a2836187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_memory_usage(df):\n",
    "    start_mem_usage = df.memory_usage().sum() / 1024 ** 2\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type.name in ['category', 'object']:\n",
    "            raise ValueError(f\"Column '{col}' is of type '{col_type.name}'\")\n",
    "\n",
    "        c_min = df[col].min()\n",
    "        c_max = df[col].max()\n",
    "        \n",
    "        if str(col_type)[:3] == 'int':\n",
    "            \n",
    "            if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                df[col] = df[col].astype(np.int8)\n",
    "                \n",
    "            elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                df[col] = df[col].astype(np.int16)\n",
    "                \n",
    "            elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                df[col] = df[col].astype(np.int32)\n",
    "                \n",
    "            elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                df[col] = df[col].astype(np.int64)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                df[col] = df[col].astype(np.float16)\n",
    "            \n",
    "            elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "            \n",
    "            else:\n",
    "                df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem_usage = df.memory_usage().sum() / 1024**2\n",
    "    print(f'------ Memory usage before: {start_mem_usage:.2f} MB')\n",
    "    print(f'------ Memory usage after: {end_mem_usage:.2f} MB')\n",
    "    print(f'------ Reduced memory usage by {(100 * (start_mem_usage - end_mem_usage) / start_mem_usage):.1f}%')\n",
    "    print('**********************' * 5)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "1842a1d3-764e-40ae-81c3-30848a4d27be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Memory usage before: 160.52 MB\n",
      "------ Memory usage after: 40.13 MB\n",
      "------ Reduced memory usage by 75.0%\n",
      "**************************************************************************************************************\n",
      "------ Memory usage before: 53.51 MB\n",
      "------ Memory usage after: 13.38 MB\n",
      "------ Reduced memory usage by 75.0%\n",
      "**************************************************************************************************************\n",
      "------ Memory usage before: 142.68 MB\n",
      "------ Memory usage after: 35.67 MB\n",
      "------ Reduced memory usage by 75.0%\n",
      "**************************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "train_df_transformed = optimize_memory_usage(train_df_transformed)\n",
    "validation_df_transformed = optimize_memory_usage(validation_df_transformed)\n",
    "test_df_transformed = optimize_memory_usage(test_df_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "2e5f8053-b3de-411f-a82c-a9434061302a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>stem-width</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.169434</td>\n",
       "      <td>-0.025772</td>\n",
       "      <td>0.196899</td>\n",
       "      <td>53</td>\n",
       "      <td>62</td>\n",
       "      <td>57</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.171509</td>\n",
       "      <td>0.107544</td>\n",
       "      <td>-0.094604</td>\n",
       "      <td>40</td>\n",
       "      <td>73</td>\n",
       "      <td>69</td>\n",
       "      <td>8</td>\n",
       "      <td>61</td>\n",
       "      <td>18</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cap-diameter  stem-height  stem-width  cap-shape  cap-surface  cap-color  \\\n",
       "0      0.169434    -0.025772    0.196899         53           62         57   \n",
       "1      0.171509     0.107544   -0.094604         40           73         69   \n",
       "\n",
       "   does-bruise-or-bleed  gill-attachment  gill-spacing  gill-color  \\\n",
       "0                     8               36            21          23   \n",
       "1                     8               61            18          40   \n",
       "\n",
       "   stem-color  has-ring  ring-type  habitat  season  \n",
       "0          42         4         13       21       3  \n",
       "1          42         4         13       18       0  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_transformed.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "61fbba06-6be3-4b17-b615-a1843f32a9e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>stem-width</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.830078</td>\n",
       "      <td>0.042816</td>\n",
       "      <td>-1.059570</td>\n",
       "      <td>36</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.218262</td>\n",
       "      <td>-0.242676</td>\n",
       "      <td>-0.580078</td>\n",
       "      <td>36</td>\n",
       "      <td>29</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>27</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cap-diameter  stem-height  stem-width  cap-shape  cap-surface  cap-color  \\\n",
       "0     -0.830078     0.042816   -1.059570         36           17         21   \n",
       "1     -0.218262    -0.242676   -0.580078         36           29         21   \n",
       "\n",
       "   does-bruise-or-bleed  gill-attachment  gill-spacing  gill-color  \\\n",
       "0                     5               12            27          30   \n",
       "1                     5               31            27          20   \n",
       "\n",
       "   stem-color  has-ring  ring-type  habitat  season  \n",
       "0          34         3         11       11       2  \n",
       "1          26         3         11       11       3  "
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df_transformed.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "9d1b353f-91b0-4f9c-979c-867ca0e7743e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-diameter</th>\n",
       "      <th>stem-height</th>\n",
       "      <th>stem-width</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>does-bruise-or-bleed</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stem-color</th>\n",
       "      <th>has-ring</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>habitat</th>\n",
       "      <th>season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.498047</td>\n",
       "      <td>1.772461</td>\n",
       "      <td>0.737305</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>44</td>\n",
       "      <td>18</td>\n",
       "      <td>66</td>\n",
       "      <td>35</td>\n",
       "      <td>52</td>\n",
       "      <td>51</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.126709</td>\n",
       "      <td>-1.880859</td>\n",
       "      <td>-0.049194</td>\n",
       "      <td>50</td>\n",
       "      <td>53</td>\n",
       "      <td>45</td>\n",
       "      <td>5</td>\n",
       "      <td>66</td>\n",
       "      <td>17</td>\n",
       "      <td>54</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cap-diameter  stem-height  stem-width  cap-shape  cap-surface  cap-color  \\\n",
       "0      0.498047     1.772461    0.737305         59           59         44   \n",
       "1      0.126709    -1.880859   -0.049194         50           53         45   \n",
       "\n",
       "   does-bruise-or-bleed  gill-attachment  gill-spacing  gill-color  \\\n",
       "0                    18               66            35          52   \n",
       "1                     5               66            17          54   \n",
       "\n",
       "   stem-color  has-ring  ring-type  habitat  season  \n",
       "0          51        17         15       16       0  \n",
       "1          38         6         14       16       0  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_transformed.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "2db7c61d-18bf-4d1e-bc9e-d4c20b5a5a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "def feature_selection(X_train, y_train, model):\n",
    "    if hasattr(model, 'coef_') or hasattr(model, 'feature_importances_'):\n",
    "        selector = SelectFromModel(model, threshold='mean')\n",
    "        selector.fit(X_train, y_train)\n",
    "        return selector.transform(X_train), selector.get_support()\n",
    "    else:\n",
    "        raise ValueError(\"Feature selection not supported for this model.\")\n",
    "\n",
    "def alternative_feature_selection(X_train, y_train):\n",
    "    selector = SelectKBest(score_func=f_classif, k='all')\n",
    "    X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "    return X_train_selected, selector.get_support()\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "#    'Logistic Regression': LogisticRegression(),\n",
    "#    'Ridge Classifier': RidgeClassifier(),\n",
    "#    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Bagging Classifier': BaggingClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'AdaBoost Classifier': AdaBoostClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'SVC': SVC(),\n",
    "#    'KNN': KNeighborsClassifier(),\n",
    "    'XGBoost': xgb.XGBClassifier(tree_method='gpu_hist'),\n",
    "    'LightGBM': lgb.LGBMClassifier(device='gpu')\n",
    "}\n",
    "\n",
    "# Define parameter grids for RandomizedSearchCV\n",
    "param_grids = {\n",
    "    'Logistic Regression': {\n",
    "        'solver': ['newton-cg', 'lbfgs', 'liblinear', 'saga'],\n",
    "        'penalty': ['l2', 'none'],  # 'elasticnet' is not supported by 'lbfgs'\n",
    "        'C': uniform(0.001, 1000),  # Inverse of regularization strength\n",
    "        'max_iter': [100, 200, 300]\n",
    "    },\n",
    "    'Ridge Classifier': {\n",
    "        'alpha': uniform(0.1, 10),  # Regularization strength\n",
    "        'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg'],\n",
    "        'fit_intercept': [True, False],\n",
    "        'max_iter': [100, 200, 300],\n",
    "       # 'normalize': [True, False]  # This should be removed as it's not a valid parameter\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'max_depth': randint(3, 20),\n",
    "    'min_samples_split': uniform(0.01, 0.1),  # Random float between 0.01 and 0.1\n",
    "    'min_samples_leaf': uniform(0.01, 0.1),  # Random float between 0.01 and 0.1\n",
    "    'min_weight_fraction_leaf': uniform(0.0, 0.1),  # Random float between 0.0 and 0.1\n",
    "    'max_features': ['auto', 'sqrt', 'log2', None],\n",
    "    'max_leaf_nodes': randint(10, 50),\n",
    "    'min_impurity_decrease': uniform(0.0, 0.1),\n",
    "    'class_weight': [None, 'balanced']\n",
    "},\n",
    "    'Bagging Classifier': {\n",
    "    'estimator': [DecisionTreeClassifier(), None],  # Default is DecisionTreeClassifier\n",
    "    'n_estimators': randint(10, 100),\n",
    "    'max_samples': uniform(0.5, 1.0),  # Random float between 0.5 and 1.0\n",
    "    'max_features': uniform(0.5, 1.0),  # Random float between 0.5 and 1.0\n",
    "    'bootstrap': [True, False],\n",
    "    'bootstrap_features': [True, False],\n",
    "    'oob_score': [True, False],\n",
    "    'n_jobs': [None, -1],\n",
    "    'random_state': [42]  # Set to None for random results, or a fixed integer for reproducibility\n",
    "},\n",
    "    'Random Forest': {\n",
    "    'n_estimators': randint(50, 300),\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, randint(3, 20)],\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 20),\n",
    "    'max_features': ['auto', 'sqrt', 'log2', uniform(0.5, 0.5)],\n",
    "    'bootstrap': [True, False],\n",
    "    'oob_score': [True, False],\n",
    "    'n_jobs': [None, -1],\n",
    "    'random_state': [42],\n",
    "    'verbose': [0, 1],\n",
    "    'warm_start': [True, False],\n",
    "    'class_weight': [None, 'balanced']\n",
    "},\n",
    "    'AdaBoost Classifier': {\n",
    "    'base_estimator': [None, DecisionTreeClassifier(max_depth=1)],\n",
    "    'n_estimators': randint(50, 300),\n",
    "    'learning_rate': uniform(0.01, 1.0),\n",
    "    'algorithm': ['SAMME', 'SAMME.R'],\n",
    "    'random_state': [42]\n",
    "},\n",
    "    'Gradient Boosting': {\n",
    "    'n_estimators': randint(50, 300),\n",
    "    'learning_rate': uniform(0.01, 0.5),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'min_samples_split': randint(2, 20),\n",
    "    'min_samples_leaf': randint(1, 20),\n",
    "    'max_features': ['sqrt', 'log2', None, uniform(0.1, 0.9)],\n",
    "    'subsample': uniform(0.5, 0.5),\n",
    "    'criterion': ['friedman_mse', 'squared_error', 'mae'],\n",
    "    #'alpha': uniform(0.5, 0.5),\n",
    "    'random_state': [42],\n",
    "    'verbose': [0, 1]\n",
    "},\n",
    "    'SVC': {\n",
    "    'C': uniform(0.1, 10),\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'degree': randint(2, 5),\n",
    "    'gamma': ['scale', 'auto', uniform(0.001, 1)],\n",
    "    'coef0': uniform(0, 10),\n",
    "    'shrinking': [True, False],\n",
    "    'probability': [True, False],\n",
    "    'tol': uniform(1e-5, 1e-1),\n",
    "    'cache_size': uniform(50, 500),\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'verbose': [True, False],\n",
    "    'max_iter': [-1, 100, 200],\n",
    "    'decision_function_shape': ['ovr', 'ovo'],\n",
    "    'break_ties': [True, False],\n",
    "    'random_state': [42]\n",
    "},\n",
    "    'KNN': {\n",
    "    'n_neighbors': randint(1, 30),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    'p': randint(1, 3),\n",
    "    'metric': ['minkowski', 'euclidean', 'manhattan', 'chebyshev', 'hamming'],\n",
    "    'leaf_size': randint(10, 50),\n",
    "    'n_jobs': [None, -1]\n",
    "},\n",
    "    'XGBoost': {\n",
    "    'n_estimators': randint(100, 300),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'subsample': uniform(0.5, 0.5),\n",
    "    'colsample_bytree': uniform(0.5, 0.5),\n",
    "    'gamma': uniform(0, 0.5),\n",
    "    'min_child_weight': randint(1, 10),\n",
    "    'reg_alpha': uniform(0, 1),\n",
    "    'reg_lambda': uniform(0, 1),\n",
    "    'scale_pos_weight': uniform(1, 10),\n",
    "    'max_delta_step': randint(0, 10),\n",
    "    'colsample_bylevel': uniform(0.5, 0.5),\n",
    "    'colsample_bynode': uniform(0.5, 0.5)\n",
    "},\n",
    "    'LightGBM': {\n",
    "    'num_leaves': randint(20, 100),\n",
    "    'max_depth': randint(3, 15),\n",
    "    'learning_rate': uniform(0.01, 0.3),\n",
    "    'n_estimators': randint(100, 300),\n",
    "    'min_child_samples': randint(10, 100),\n",
    "    'min_split_gain': uniform(0, 0.5),\n",
    "    'subsample': uniform(0.5, 0.5),\n",
    "    'subsample_freq': randint(1, 10),\n",
    "    'colsample_bytree': uniform(0.5, 0.5),\n",
    "    'colsample_bylevel': uniform(0.5, 0.5),\n",
    "    'reg_alpha': uniform(0, 1),\n",
    "    'reg_lambda': uniform(0, 1),\n",
    "    'scale_pos_weight': uniform(1, 10)\n",
    "}\n",
    "}\n",
    "\n",
    "# Optuna objective function for XGBoost and LightGBM\n",
    "def objective(trial, model_name, model, X_train, y_train, X_val, y_val):\n",
    "    if model_name == 'XGBoost':\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "            'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "            'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 0.3),\n",
    "            'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "            'gamma': trial.suggest_uniform('gamma', 0, 0.5),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "            'reg_alpha': trial.suggest_uniform('reg_alpha', 0, 1),\n",
    "            'reg_lambda': trial.suggest_uniform('reg_lambda', 0, 1),\n",
    "            'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 1, 10),\n",
    "            'max_delta_step': trial.suggest_int('max_delta_step', 0, 10),\n",
    "            'colsample_bylevel': trial.suggest_uniform('colsample_bylevel', 0.5, 1.0),\n",
    "            'colsample_bynode': trial.suggest_uniform('colsample_bynode', 0.5, 1.0)\n",
    "        }\n",
    "    elif model_name == 'LightGBM':\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "            'learning_rate': trial.suggest_uniform('learning_rate', 0.01, 0.3),\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 31, 127),\n",
    "            'max_depth': trial.suggest_int('max_depth', -1, 15),\n",
    "            'subsample': trial.suggest_uniform('subsample', 0.5, 1.0),\n",
    "            'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.5, 1.0),\n",
    "            'reg_alpha': trial.suggest_uniform('reg_alpha', 0, 0.2),\n",
    "            'reg_lambda': trial.suggest_uniform('reg_lambda', 0, 0.2),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 10, 100),\n",
    "            'min_split_gain': trial.suggest_uniform('min_split_gain', 0, 0.5),\n",
    "            'subsample_freq': trial.suggest_int('subsample_freq', 1, 10),\n",
    "            'colsample_bylevel': trial.suggest_uniform('colsample_bylevel', 0.5, 1.0),\n",
    "            'scale_pos_weight': trial.suggest_uniform('scale_pos_weight', 1, 10)\n",
    "        }\n",
    "\n",
    "    model.set_params(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_val)\n",
    "    score = matthews_corrcoef(y_val, preds)\n",
    "    return score\n",
    "\n",
    "# Hyperparameter tuning using RandomizedSearchCV\n",
    "def tune_model(model_name, model, param_grid, X_train, y_train):\n",
    "    search = RandomizedSearchCV(\n",
    "        model, param_distributions=param_grid, n_iter=10, scoring='f1', cv=3, random_state=42\n",
    "    )\n",
    "    search.fit(X_train, y_train)\n",
    "    print(f\"{model_name} Best Parameters (Random Search): {search.best_params_}\")  # Print best parameters\n",
    "    return search.best_estimator_, search.best_params_\n",
    "\n",
    "# Hyperparameter tuning using Optuna for XGBoost and LightGBM\n",
    "def optuna_tune_model(model_name, model, X_train, y_train, X_val, y_val):\n",
    "    study = optuna.create_study(direction='maximize', sampler=TPESampler())\n",
    "    study.optimize(lambda trial: objective(trial, model_name, model, X_train, y_train, X_val, y_val), n_trials=50)\n",
    "    print(f\"{model_name} Best Parameters (Optuna): {study.best_params}\")  # Print best parameters\n",
    "    return study.best_params\n",
    "\n",
    "# Train and evaluate models\n",
    "def evaluate_models(X_train, y_train, X_val, y_val):\n",
    "    best_models = {}\n",
    "    for name, model in models.items():\n",
    "        logger.info(f\"Evaluating {name}\")\n",
    "\n",
    "        # Feature Selection\n",
    "        if hasattr(model, 'coef_') or hasattr(model, 'feature_importances_'):\n",
    "            logger.info(f\"Performing feature selection for {name}\")\n",
    "            X_train_selected, support = feature_selection(X_train, y_train, model)\n",
    "            X_val_selected = X_val.iloc[:, support]\n",
    "        else:\n",
    "            logger.info(f\"Skipping feature selection for {name} due to lack of support\")\n",
    "            X_train_selected = X_train\n",
    "            X_val_selected = X_val\n",
    "\n",
    "        if name in ['XGBoost', 'LightGBM']:\n",
    "            # Perform Random Search\n",
    "            best_model, best_params_random = tune_model(name, model, param_grids[name], X_train_selected, y_train)\n",
    "            train_preds_random = best_model.predict(X_train_selected)\n",
    "            val_preds_random = best_model.predict(X_val_selected)\n",
    "            train_score_random = matthews_corrcoef(y_train, train_preds_random)\n",
    "            val_score_random = matthews_corrcoef(y_val, val_preds_random)\n",
    "            logger.info(f\"{name} (Random Search) - Train MCC Score: {train_score_random:.4f}\")\n",
    "            logger.info(f\"{name} (Random Search) - Validation MCC Score: {val_score_random:.4f}\")\n",
    "            \n",
    "            # Perform Bayesian Search (Optuna)\n",
    "            params_optuna = optuna_tune_model(name, model, X_train_selected, y_train, X_val_selected, y_val)\n",
    "            model.set_params(**params_optuna)\n",
    "            model.fit(X_train_selected, y_train)\n",
    "            train_preds_optuna = model.predict(X_train_selected)\n",
    "            val_preds_optuna = model.predict(X_val_selected)\n",
    "            train_score_optuna = matthews_corrcoef(y_train, train_preds_optuna)\n",
    "            val_score_optuna = matthews_corrcoef(y_val, val_preds_optuna)\n",
    "            logger.info(f\"{name} (Optuna) - Train MCC Score: {train_score_optuna:.4f}\")\n",
    "            logger.info(f\"{name} (Optuna) - Validation MCC Score: {val_score_optuna:.4f}\")\n",
    "            logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "            \n",
    "        else:\n",
    "            # Hyperparameter tuning using RandomizedSearchCV\n",
    "            best_model, best_params = tune_model(name, model, param_grids[name], X_train_selected, y_train)\n",
    "            model = best_model\n",
    "            train_preds = model.predict(X_train_selected)\n",
    "            val_preds = model.predict(X_val_selected)\n",
    "            train_score = matthews_corrcoef(y_train, train_preds)\n",
    "            val_score = matthews_corrcoef(y_val, val_preds)\n",
    "            logger.info(f\"{name} - Train MCC Score: {train_score:.4f}\")\n",
    "            logger.info(f\"{name} - Validation MCC Score: {val_score:.4f}\")\n",
    "            logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "        best_models[name] = model\n",
    "\n",
    "    return best_models\n",
    "\n",
    "# Testing best models on the test set\n",
    "def test_best_models(best_models, X_train, y_train, X_val, y_val):\n",
    "    results = {}\n",
    "    for name, model in best_models.items():\n",
    "        # Training predictions and score\n",
    "        train_preds = model.predict(X_train)\n",
    "        train_score = matthews_corrcoef(y_train, train_preds)\n",
    "\n",
    "        # Validation predictions and score\n",
    "        val_preds = model.predict(X_val)\n",
    "        val_score = matthews_corrcoef(y_val, val_preds)\n",
    "\n",
    "        # Logging the scores\n",
    "        logger.info(f\"{name} - Train MCC Score: {train_score:.4f}\")\n",
    "        logger.info(f\"{name} - Validation MCC Score: {val_score:.4f}\")\n",
    "        logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "        # Storing the results\n",
    "        results[name] = {\n",
    "            'train_score': train_score,\n",
    "            'val_score': val_score,\n",
    "            #'test_score': test_score\n",
    "        }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "7d0fce02-416a-4a58-8076-79e1df0fc7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Evaluating Bagging Classifier\n",
      "INFO:__main__:Skipping feature selection for Bagging Classifier due to lack of support\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[238], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate models\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m best_models \u001b[38;5;241m=\u001b[39m evaluate_models(train_df_transformed, y_train, validation_df_transformed, y_val)\n\u001b[0;32m      4\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel evaluation completed. Time elapsed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[236], line 258\u001b[0m, in \u001b[0;36mevaluate_models\u001b[1;34m(X_train, y_train, X_val, y_val)\u001b[0m\n\u001b[0;32m    254\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime elapsed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;66;03m# Hyperparameter tuning using RandomizedSearchCV\u001b[39;00m\n\u001b[1;32m--> 258\u001b[0m     best_model, best_params \u001b[38;5;241m=\u001b[39m tune_model(name, model, param_grids[name], X_train_selected, y_train)\n\u001b[0;32m    259\u001b[0m     model \u001b[38;5;241m=\u001b[39m best_model\n\u001b[0;32m    260\u001b[0m     train_preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_train_selected)\n",
      "Cell \u001b[1;32mIn[236], line 207\u001b[0m, in \u001b[0;36mtune_model\u001b[1;34m(model_name, model, param_grid, X_train, y_train)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtune_model\u001b[39m(model_name, model, param_grid, X_train, y_train):\n\u001b[0;32m    204\u001b[0m     search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m    205\u001b[0m         model, param_distributions\u001b[38;5;241m=\u001b[39mparam_grid, n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[0;32m    206\u001b[0m     )\n\u001b[1;32m--> 207\u001b[0m     search\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Best Parameters (Random Search): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msearch\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Print best parameters\u001b[39;00m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m search\u001b[38;5;241m.\u001b[39mbest_estimator_, search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1914\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1914\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1915\u001b[0m         ParameterSampler(\n\u001b[0;32m   1916\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_distributions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[0;32m   1917\u001b[0m         )\n\u001b[0;32m   1918\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:916\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    912\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    914\u001b[0m     )\n\u001b[1;32m--> 916\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    917\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    918\u001b[0m         clone(base_estimator),\n\u001b[0;32m    919\u001b[0m         X,\n\u001b[0;32m    920\u001b[0m         y,\n\u001b[0;32m    921\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    922\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    923\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    924\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    925\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    927\u001b[0m     )\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    929\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    930\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    931\u001b[0m     )\n\u001b[0;32m    932\u001b[0m )\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    935\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    936\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    938\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    939\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    893\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 895\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    899\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_bagging.py:334\u001b[0m, in \u001b[0;36mBaseBagging.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;66;03m# Convert data (X is required to be 2d and indexable)\u001b[39;00m\n\u001b[0;32m    326\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    327\u001b[0m     X,\n\u001b[0;32m    328\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    332\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    333\u001b[0m )\n\u001b[1;32m--> 334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_samples, sample_weight\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_bagging.py:469\u001b[0m, in \u001b[0;36mBaseBagging._fit\u001b[1;34m(self, X, y, max_samples, max_depth, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    466\u001b[0m seeds \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mrandint(MAX_INT, size\u001b[38;5;241m=\u001b[39mn_more_estimators)\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_seeds \u001b[38;5;241m=\u001b[39m seeds\n\u001b[1;32m--> 469\u001b[0m all_results \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[0;32m    470\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parallel_args()\n\u001b[0;32m    471\u001b[0m )(\n\u001b[0;32m    472\u001b[0m     delayed(_parallel_build_estimators)(\n\u001b[0;32m    473\u001b[0m         n_estimators[i],\n\u001b[0;32m    474\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    475\u001b[0m         X,\n\u001b[0;32m    476\u001b[0m         y,\n\u001b[0;32m    477\u001b[0m         sample_weight,\n\u001b[0;32m    478\u001b[0m         seeds[starts[i] : starts[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]],\n\u001b[0;32m    479\u001b[0m         total_n_estimators,\n\u001b[0;32m    480\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    481\u001b[0m         check_input\u001b[38;5;241m=\u001b[39mcheck_input,\n\u001b[0;32m    482\u001b[0m     )\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_jobs)\n\u001b[0;32m    484\u001b[0m )\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# Reduce\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m    488\u001b[0m     itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(t[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m all_results)\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluate models\n",
    "best_models = evaluate_models(train_df_transformed, y_train, validation_df_transformed, y_val)\n",
    "\n",
    "logger.info(f\"Model evaluation completed. Time elapsed: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49c8866-3814-4340-b566-0ab6a5f28842",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a748160c-ca2c-4c20-bffd-9738487ab4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = test_best_models(best_models, train_df_transformed, y_train, validation_df_transformed, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3878789b-0ccd-4b76-8001-7df92b6ef9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logging\n",
    "logging.info(\"Starting cross-validation process\")\n",
    "logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Sort the models by their validation scores in descending order\n",
    "sorted_test_models = sorted(results.items(), key=lambda item: item[1]['val_score'], reverse=True)\n",
    "\n",
    "# Select the top 5 models based on validation scores\n",
    "five_best_models = {model_name: scores for model_name, scores in sorted_test_models[:5]}\n",
    "\n",
    "# Output the best five models based on validation scores\n",
    "for model_name, scores in five_best_models.items():\n",
    "    print(f\"Model: {model_name}, Validation MCC Score: {scores['val_score']}, Train MCC Score: {scores['train_score']}\")\n",
    "\n",
    "# The best_five_test_models dictionary now contains the top five models based on validation data performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f2c4e59-ac0f-4900-9197-e5b0a09c5061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting cross-validation process\n",
      "INFO:__main__:Time elapsed: 121.60 seconds\n"
     ]
    }
   ],
   "source": [
    "# logger.info(\"Starting cross-validation process\")\n",
    "# logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# # Dictionary of the five best models based on the provided results\n",
    "# five_best_models = {\n",
    "#     'Bagging Classifier': BaggingClassifier(base_estimator=None, bootstrap=False,\n",
    "#                                             max_features=0.6039708314340944,\n",
    "#                                             max_samples=0.7838501639099957, n_estimators=72, n_jobs=-1,\n",
    "#                                             random_state=42),\n",
    "#     'Random Forest': RandomForestClassifier(class_weight='balanced', max_features='log2',\n",
    "#                                             min_samples_leaf=8, min_samples_split=8,\n",
    "#                                             n_estimators=171, oob_score=True, random_state=42,\n",
    "#                                             warm_start=True),\n",
    "#     'XGBoost': XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
    "#                              colsample_bylevel=0.7324201991368923,\n",
    "#                              colsample_bynode=0.6984067959652569,\n",
    "#                              colsample_bytree=0.6585770133495129, device=None,\n",
    "#                              early_stopping_rounds=None, enable_categorical=False,\n",
    "#                              eval_metric=None, feature_types=None, gamma=0.3990553580730866,\n",
    "#                              grow_policy=None, importance_type=None,\n",
    "#                              interaction_constraints=None, learning_rate=0.23958788518583604,\n",
    "#                              max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
    "#                              max_delta_step=5, max_depth=9, max_leaves=None,\n",
    "#                              min_child_weight=8, monotone_constraints=None,\n",
    "#                              multi_strategy=None, n_estimators=202, n_jobs=None,\n",
    "#                              num_parallel_tree=None, random_state=None),\n",
    "#     'LightGBM': LGBMClassifier(colsample_bytree=0.7085181455028883, device='gpu',\n",
    "#                                learning_rate=0.09554089088242068, max_depth=11,\n",
    "#                                min_child_samples=26, min_split_gain=0.18636874352935062,\n",
    "#                                n_estimators=233, num_leaves=117, reg_alpha=0.19897165336160308,\n",
    "#                                reg_lambda=0.13427322639962427,\n",
    "#                                scale_pos_weight=1.0239900845521561, subsample=0.595271788428719,\n",
    "#                                subsample_freq=8),\n",
    "#     'Gradient Boosting': GradientBoostingClassifier(criterion='squared_error',\n",
    "#                                                     learning_rate=0.1009124836035503, max_depth=7,\n",
    "#                                                     max_features='sqrt', min_samples_leaf=12,\n",
    "#                                                     min_samples_split=13, n_estimators=138,\n",
    "#                                                     random_state=42, subsample=0.645614570099021)\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c42e21-4d3b-4b92-97bf-2b8cc8c4cfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_sub = pd.read_csv('test.csv')\n",
    "test_df_sub.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de542ae-da1e-4476-8f06-2d5f5e300ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Train_ML function\n",
    "def Train_ML(Model, X, y, test_data):\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    train_scores = []\n",
    "    val_scores = []\n",
    "    test_predictions = []\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X, y), 1):\n",
    "        # Handle indexing based on the type of X and y\n",
    "        if isinstance(X, pd.DataFrame) or isinstance(X, pd.Series):\n",
    "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        else:\n",
    "            X_train, X_val = X[train_index], X[val_index]\n",
    "        \n",
    "        if isinstance(y, pd.Series):\n",
    "            y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        else:\n",
    "            y_train, y_val = y[train_index], y[val_index]\n",
    "        \n",
    "        Model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = Model.predict(X_train)\n",
    "        train_mcc = matthews_corrcoef(y_train, y_train_pred)\n",
    "        train_scores.append(train_mcc)\n",
    "\n",
    "        y_val_pred = Model.predict(X_val)\n",
    "        val_mcc = matthews_corrcoef(y_val, y_val_pred)\n",
    "        val_scores.append(val_mcc)\n",
    "        \n",
    "        y_test_pred_proba = Model.predict(test_data)\n",
    "        test_predictions.append(y_test_pred_proba)\n",
    "\n",
    "        print(f\"Fold {fold}: Train MCC = {train_mcc:.6f}, Validation MCC = {val_mcc:.6f}\")\n",
    "        logger.info(f\"Fold {fold}: Train MCC = {train_mcc:.6f}, Validation MCC = {val_mcc:.6f}\")\n",
    "        logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    mean_train_mcc = np.mean(train_scores)\n",
    "    mean_val_mcc = np.mean(val_scores)\n",
    "\n",
    "    print(f\"\\nMean Train MCC: {mean_train_mcc:.6f}\")\n",
    "    print(f\"Mean Validation MCC: {mean_val_mcc:.6f}\")\n",
    "    logger.info(f\"Mean Train MCC: {mean_train_mcc:.6f}, Mean Validation MCC: {mean_val_mcc:.6f}\")\n",
    "    logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    return Model, test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97755317-72dd-4a73-a3f1-b50c22b76021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Starting model training and cross-validation for Bagging Classifier\n",
      "INFO:__main__:Fold 1: Train MCC = 0.998967, Validation MCC = 0.982903\n",
      "INFO:__main__:Time elapsed: 4064.17 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Train MCC = 0.998967, Validation MCC = 0.982903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Fold 2: Train MCC = 0.998962, Validation MCC = 0.982966\n",
      "INFO:__main__:Time elapsed: 4633.79 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2: Train MCC = 0.998962, Validation MCC = 0.982966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Fold 3: Train MCC = 0.998976, Validation MCC = 0.982578\n",
      "INFO:__main__:Time elapsed: 5200.86 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3: Train MCC = 0.998976, Validation MCC = 0.982578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Fold 4: Train MCC = 0.998988, Validation MCC = 0.982705\n",
      "INFO:__main__:Time elapsed: 5761.81 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4: Train MCC = 0.998988, Validation MCC = 0.982705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Fold 5: Train MCC = 0.998979, Validation MCC = 0.982979\n",
      "INFO:__main__:Time elapsed: 6330.73 seconds\n",
      "INFO:__main__:Mean Train MCC: 0.998974, Mean Validation MCC: 0.982826\n",
      "INFO:__main__:Time elapsed: 6330.74 seconds\n",
      "INFO:__main__:Bagging Classifier - Test predictions done\n",
      "INFO:__main__:Time elapsed: 6330.87 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5: Train MCC = 0.998979, Validation MCC = 0.982979\n",
      "\n",
      "Mean Train MCC: 0.998974\n",
      "Mean Validation MCC: 0.982826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Generated output file for Bagging Classifier\n",
      "INFO:__main__:Time elapsed: 6333.49 seconds\n",
      "INFO:__main__:Starting model training and cross-validation for Random Forest\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      4\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting model training and cross-validation for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     trained_model, test_preds \u001b[38;5;241m=\u001b[39m \u001b[43mTrain_ML\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_df_transformed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_df_transformed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Averaging predictions across all folds\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     final_test_preds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(test_preds, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[27], line 20\u001b[0m, in \u001b[0;36mTrain_ML\u001b[1;34m(Model, X, y, test_data)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m     y_train, y_val \u001b[38;5;241m=\u001b[39m y[train_index], y[val_index]\n\u001b[1;32m---> 20\u001b[0m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m y_train_pred \u001b[38;5;241m=\u001b[39m Model\u001b[38;5;241m.\u001b[39mpredict(X_train)\n\u001b[0;32m     23\u001b[0m train_mcc \u001b[38;5;241m=\u001b[39m matthews_corrcoef(y_train, y_train_pred)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:188\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    186\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 188\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\sklearn\\tree\\_classes.py:959\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    930\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    931\u001b[0m \n\u001b[0;32m    932\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 959\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    965\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\gpu_env2\\lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Perform cross-validation, fit on the entire training data, and predict for each model\n",
    "for model_name, model in five_best_models.items():\n",
    "    try:\n",
    "        logger.info(f\"Starting model training and cross-validation for {model_name}\")\n",
    "        trained_model, test_preds = Train_ML(model, train_df_transformed, y_train, test_df_transformed)\n",
    "\n",
    "        # Averaging predictions across all folds\n",
    "        final_test_preds = np.mean(test_preds, axis=0)\n",
    "        final_test_preds_binary = (final_test_preds >= 0.5).astype(int)\n",
    "        \n",
    "        # Inverse transform the predictions to get the original class labels\n",
    "        predictions = label_encoder.inverse_transform(final_test_preds_binary)\n",
    "\n",
    "        # Log the prediction output\n",
    "        logger.info(f\"{model_name} - Test predictions done\")\n",
    "        logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "        # Output predictions to a CSV file\n",
    "        output_df = pd.DataFrame({'id': test_df_sub['id'], 'class': predictions})\n",
    "        output_df.to_csv(f'Submission_01A_Dropped_Simple_{model_name}.csv', index=False)\n",
    "        logger.info(f\"Generated output file for {model_name}\")\n",
    "        logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred with {model_name}: {e}\")\n",
    "        logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Print completion message\n",
    "print(\"Predictions for all five models have been saved to individual CSV files.\")\n",
    "logger.info(\"Predictions for all five models have been saved to individual CSV files.\")\n",
    "logger.info(f\"Total Time elapsed: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3571508b-b088-4366-a96f-0841b59fd7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MCC as the scoring metric\n",
    "mcc_scorer = make_scorer(matthews_corrcoef)\n",
    "\n",
    "# Perform cross-validation, fit on the entire training data, and predict for each model\n",
    "predictions = {}\n",
    "for model_name, model in five_best_models.items():\n",
    "    try:\n",
    "        logging.info(f\"Performing cross-validation for {model_name}\")\n",
    "        scores = cross_val_score(model, train_df_transformed, y_train, cv=5, scoring=mcc_scorer, n_jobs=-1)\n",
    "        logging.info(f\"{model_name} - CV Scores: {scores}\")\n",
    "        logging.info(f\"{model_name} - Mean CV Score: {np.mean(scores)}\")\n",
    "        logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "        # Fit the model on the entire training data\n",
    "        model.fit(train_df_transformed, y_train)\n",
    "    \n",
    "        # Predict the output for test_df_transformed\n",
    "        preds = model.predict(test_df_transformed)\n",
    "\n",
    "        # Inverse transform the predictions to get the original class labels\n",
    "        predictions[model_name] = label_encoder.inverse_transform(preds)\n",
    "\n",
    "        # Log the prediction output\n",
    "        logging.info(f\"{model_name} - Test predictions done for {model_name}\")\n",
    "        logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "        # Output predictions to a CSV file\n",
    "        output_df = pd.DataFrame({'id': test_df_sub['id'], 'class': predictions[model_name]})\n",
    "        output_df.to_csv(f'Submission_01A(2)_Dropped_Simple_{model_name}.csv', index=False)\n",
    "        print(output_df.head(2))\n",
    "        logger.info(f\"Generated output file - Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"An error occurred with {model_name}: {e}\")\n",
    "        logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Print completion message\n",
    "print(\"Predictions for all five models have been saved to individual CSV files.\")\n",
    "print(\"Predictions for all five models have been saved to individual CSV files.\")\n",
    "logger.info(f\"Time elapsed: {time.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2a8f0c-a84f-4ee4-811a-64c9647e8718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
